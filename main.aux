\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\@gls@reference{acronym}{hls}{\glsseeformat[Glossary:]{hlsg}{}}
\@gls@reference{acronym}{rtl}{\glsseeformat[Glossary:]{rtlg}{}}
\@gls@reference{acronym}{asic}{\glsseeformat[Glossary:]{asicg}{}}
\@gls@reference{acronym}{eda}{\glsseeformat[Glossary:]{edag}{}}
\@gls@reference{acronym}{fpga}{\glsseeformat[Glossary:]{fpgag}{}}
\@gls@reference{acronym}{lut}{\glsseeformat[Glossary:]{lutg}{}}
\@gls@reference{acronym}{par}{\glsseeformat[Glossary:]{parg}{}}
\@gls@reference{acronym}{ff}{\glsseeformat[Glossary:]{ffg}{}}
\@gls@reference{acronym}{bram}{\glsseeformat[Glossary:]{bramg}{}}
\@gls@reference{acronym}{rom}{\glsseeformat[Glossary:]{romg}{}}
\@gls@reference{acronym}{pe}{\glsseeformat[Glossary:]{peg}{}}
\@gls@reference{acronym}{fft}{\glsseeformat[Glossary:]{fftg}{}}
\@gls@reference{acronym}{dft}{\glsseeformat[Glossary:]{dftg}{}}
\@gls@reference{acronym}{crs}{\glsseeformat[Glossary:]{crsg}{}}
\@gls@reference{acronym}{ssa}{\glsseeformat[Glossary:]{ssag}{}}
\providecommand\@gls@reference[3]{}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{main}{dftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{4}}
\citation{micheli1994synthesis,gupta2004spark,coussy2010high,gajski2012high}
\@writefile{toc}{\contentsline {chapter}{Preface}{7}{chapter*.2}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{9}{chapter*.3}}
\citation{mead1980introduction}
\citation{lee2017plato}
\citation{knapp96bc}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{11}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:introduction}{{1}{11}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}High-level Synthesis (HLS)}{11}{section.1.1}}
\@gls@reference{acronym}{eda}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{main}{edag}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{main}{rtlg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{eda}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{main}{fpgag}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{main}{hlsg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\citation{canis2011legup}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{11}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\citation{ultrascaleArchConfig}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{synth}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{netlist}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{netlist}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{par}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{parg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{bitstream}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{bitstream}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}FPGA Architecture}{13}{section.1.2}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{main}{lutg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Part a) shows a 2 input \gls {lut}, i.e., a 2-LUT. Each of the four configuration bits can be programmed to change the function of the 2-LUT making it a fully programmable 2 input logic gate. Part b) provides a sample programming to implement an AND gate. The values in the ``out'' column from top to bottom correspond directly to configuration bits 0 through 3. Part c) shows a simple \gls {slice} that contains a slightly more complex 3-LUT with the possibility of storing the output into a \gls {ff}. Note that there are nine configuration bits: eight to program the 3-LUT and one to decide whether the output should be direct from the 3-LUT or the one stored in the \gls {ff}. More generally, a \gls {slice} is defined as a small number of \glspl {lut} and \glspl {ff} combined with routing logic (multiplexers) to move inputs, outputs, and internal values between the \glspl {lut} and \glspl {ff}.\relax }}{14}{figure.caption.4}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{ffg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lut}{{1.1}{14}{Part a) shows a 2 input \gls {lut}, i.e., a 2-LUT. Each of the four configuration bits can be programmed to change the function of the 2-LUT making it a fully programmable 2 input logic gate. Part b) provides a sample programming to implement an AND gate. The values in the ``out'' column from top to bottom correspond directly to configuration bits 0 through 3. Part c) shows a simple \gls {slice} that contains a slightly more complex 3-LUT with the possibility of storing the output into a \gls {ff}. Note that there are nine configuration bits: eight to program the 3-LUT and one to decide whether the output should be direct from the 3-LUT or the one stored in the \gls {ff}. More generally, a \gls {slice} is defined as a small number of \glspl {lut} and \glspl {ff} combined with routing logic (multiplexers) to move inputs, outputs, and internal values between the \glspl {lut} and \glspl {ff}.\relax }{figure.caption.4}{}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{13}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\citation{brown1996fpga,betz1997vpr,hauck2010reconfigurable}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  A \gls {slice} contains a small number of \glspl {lut} and \gls {ff}. We show a very simple \gls {slice} with one \gls {lut} and one \gls {ff} though generally these have two or more of each. Slices are connected to one another using a \gls {routingchannel} and \gls {switchbox}. These two provide a programmable interconnect that provide the data movement between the programmable logic elements (\glspl {slice}). The \gls {switchbox} has many switches (typically implemented as pass transistors) that allow for arbitrary wiring configurations between the different routing tracks in the routing tracks adjacent to the switchbox. \relax }}{15}{figure.caption.5}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\newlabel{fig:slice_channel}{{1.2}{15}{A \gls {slice} contains a small number of \glspl {lut} and \gls {ff}. We show a very simple \gls {slice} with one \gls {lut} and one \gls {ff} though generally these have two or more of each. Slices are connected to one another using a \gls {routingchannel} and \gls {switchbox}. These two provide a programmable interconnect that provide the data movement between the programmable logic elements (\glspl {slice}). The \gls {switchbox} has many switches (typically implemented as pass transistors) that allow for arbitrary wiring configurations between the different routing tracks in the routing tracks adjacent to the switchbox. \relax }{figure.caption.5}{}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces  The two-dimensional structure of an \gls {fpga} showing an island style architecture. The logic and memory resources in the \glspl {slice} are interconnected using \glspl {routingchannel} and \glspl {switchbox}. The input/output (I/O) blocks provide an external interface, e.g., to a memory, microprocessor, sensor, and/or actuator. On some FPGAs, the I/O directly connects to the chip pins. Other FPGAs use the I/O to connect the programmable logic fabric to on-chip resources (e.g., a microprocessor bus or cache). \relax }}{16}{figure.caption.6}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\newlabel{fig:fpga}{{1.3}{16}{The two-dimensional structure of an \gls {fpga} showing an island style architecture. The logic and memory resources in the \glspl {slice} are interconnected using \glspl {routingchannel} and \glspl {switchbox}. The input/output (I/O) blocks provide an external interface, e.g., to a memory, microprocessor, sensor, and/or actuator. On some FPGAs, the I/O directly connects to the chip pins. Other FPGAs use the I/O to connect the programmable logic fabric to on-chip resources (e.g., a microprocessor bus or cache). \relax }{figure.caption.6}{}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{slice}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{switchbox}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{main}{ioblock}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces  Modern \glspl {fpga} are becoming more heterogenous with a mix of programmable logic elements and ``hardened'' architectural elements like register files, custom datapaths, and high speed interconnect. The \gls {fpga} is often paired with one or more microprocessors, e.g., ARM or x86 cores, that coordinates the control of the system. \relax }}{17}{figure.caption.7}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\newlabel{fig:heterogenous_fpga}{{1.4}{17}{Modern \glspl {fpga} are becoming more heterogenous with a mix of programmable logic elements and ``hardened'' architectural elements like register files, custom datapaths, and high speed interconnect. The \gls {fpga} is often paired with one or more microprocessors, e.g., ARM or x86 cores, that coordinates the control of the system. \relax }{figure.caption.7}{}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces A comparison of three different on- and off-chip memory storage options. External memory provides the most density but has limited total bandwidth. Moving on-chip there are two options: \glspl {ff} and \glspl {bram}. \glspl {ff} have the best total bandwidth but only a limited amount of total data storage capability. \glspl {bram} provide an intermediate value between external memory and \glspl {ff}.\relax }}{18}{figure.caption.8}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\newlabel{fig:FPGAmemories}{{1.5}{18}{A comparison of three different on- and off-chip memory storage options. External memory provides the most density but has limited total bandwidth. Moving on-chip there are two options: \glspl {ff} and \glspl {bram}. \glspl {ff} have the best total bandwidth but only a limited amount of total data storage capability. \glspl {bram} provide an intermediate value between external memory and \glspl {ff}.\relax }{figure.caption.8}{}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces A block diagram showing a hypothetical embedded FPGA design, consisting of I/O interface cores (shown in blue), standard cores (shown in green), and application specific accelerator cores (shown in purple). Note that accelerator cores might have streaming interfaces (Accelerator 2), memory-mapped interfaces (Accelerator 3), or both (Accelerator 1). \relax }}{19}{figure.caption.9}}
\newlabel{fig:designTemplate}{{1.6}{19}{A block diagram showing a hypothetical embedded FPGA design, consisting of I/O interface cores (shown in blue), standard cores (shown in green), and application specific accelerator cores (shown in purple). Note that accelerator cores might have streaming interfaces (Accelerator 2), memory-mapped interfaces (Accelerator 3), or both (Accelerator 1). \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}FPGA Design Process}{19}{section.1.3}}
\@gls@reference{main}{core}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Design Optimization}{20}{section.1.4}}
\newlabel{sec:designOptimization}{{1.4}{20}{Design Optimization}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Performance Characterization}{20}{subsection.1.4.1}}
\newlabel{sec:designCharacterization}{{1.4.1}{20}{Performance Characterization}{subsection.1.4.1}{}}
\@gls@reference{main}{task}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{task-latency}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{task-interval}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces The task interval and task latency for two different designs. The left design is pipelined while the right one uses a more sequential implementation.\relax }}{21}{figure.caption.10}}
\newlabel{fig:intervalDuration}{{1.7}{21}{The task interval and task latency for two different designs. The left design is pipelined while the right one uses a more sequential implementation.\relax }{figure.caption.10}{}}
\@gls@reference{main}{data-rate}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@gls@reference{main}{task-interval}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Area/Throughput Tradeoffs}{22}{subsection.1.4.2}}
\newlabel{sec:filterThroughputTradeoffs}{{1.4.2}{22}{Area/Throughput Tradeoffs}{subsection.1.4.2}{}}
\@gls@reference{main}{fir}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{22}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir.c}{23}{lstlisting.1.-1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Code for a four tap FIR filter. \relax }}{23}{figure.caption.11}}
\newlabel{fig:FIR}{{1.8}{23}{Code for a four tap FIR filter. \relax }{figure.caption.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir.S}{24}{lstlisting.1.-2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces RISC-style assembly generated from the C code in Figure \ref  {fig:FIR}, targetting the Xilinx Microblaze processor. This code is generated using \texttt  {microblazeel-xilinx-linux-gnu-gcc -O1 -mno-xl-soft-mul -S fir.c}\relax }}{24}{figure.caption.12}}
\newlabel{fig:FIR_microblaze}{{1.9}{24}{RISC-style assembly generated from the C code in Figure \ref {fig:FIR}, targetting the Xilinx Microblaze processor. This code is generated using \texttt {microblazeel-xilinx-linux-gnu-gcc -O1 -mno-xl-soft-mul -S fir.c}\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces A ``one tap per clock'' architecture for an FIR filter. This architecture can be implemented from the code in Figure \ref  {fig:FIR}.\relax }}{25}{figure.caption.13}}
\newlabel{fig:FIR_sequential}{{1.10}{25}{A ``one tap per clock'' architecture for an FIR filter. This architecture can be implemented from the code in Figure \ref {fig:FIR}.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces A ``one sample per clock'' architecture for an FIR filter. This architecture can be implemented from the code in Figure \ref  {fig:FIR} using function pipeline.\relax }}{25}{figure.caption.14}}
\newlabel{fig:FIR_function_pipeline}{{1.11}{25}{A ``one sample per clock'' architecture for an FIR filter. This architecture can be implemented from the code in Figure \ref {fig:FIR} using function pipeline.\relax }{figure.caption.14}{}}
\citation{papaefthymiou91,leiserson93}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Restrictions on Processing Rate}{26}{subsection.1.4.3}}
\@gls@reference{main}{recurrence}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{26}}
\@writefile{lol}{\contentsline {lstlisting}{examples/block\textunderscore fir.c}{27}{lstlisting.1.-3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Alternative code implementing an FIR filter.\relax }}{27}{figure.caption.15}}
\newlabel{fig:block_FIR}{{1.12}{27}{Alternative code implementing an FIR filter.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Coding Style}{27}{subsection.1.4.4}}
\citation{mataidesigning,matai2energy,cong2011high,chen2012fpga,lee250high}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Restructured Code}{28}{section.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Book Organization}{28}{section.1.6}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces A map describing the types of HLS optimizations and the chapters that discuss the concepts beyond them.\relax }}{30}{table.caption.16}}
\newlabel{table:optimizations}{{1.1}{30}{A map describing the types of HLS optimizations and the chapters that discuss the concepts beyond them.\relax }{table.caption.16}{}}
\citation{lee2011signalsandsystems}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Finite Impulse Response (FIR) Filters}{31}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:fir}{{2}{31}{Finite Impulse Response (FIR) Filters}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Overview}{31}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Background}{32}{section.2.2}}
\citation{kastner2010arithmetic}
\citation{mirzaei2007fpga}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Base FIR Architecture}{33}{section.2.3}}
\newlabel{sec:base_fir}{{2.3}{33}{Base FIR Architecture}{section.2.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir11\textunderscore initial.c}{34}{lstlisting.2.-4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A functionally correct, but highly unoptimized, implementation of an 11 tap FIR filter. \relax }}{34}{figure.caption.17}}
\newlabel{fig:fir11_initial}{{2.1}{34}{A functionally correct, but highly unoptimized, implementation of an 11 tap FIR filter. \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Calculating Performance}{35}{section.2.4}}
\newlabel{sec:fir-performance}{{2.4}{35}{Calculating Performance}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Operation Chaining}{36}{section.2.5}}
\newlabel{sec:fir-chaining}{{2.5}{36}{Operation Chaining}{section.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The performance of multiply accumulate operation changes depending upon the target clock period. Assume the \lstinline {multiply} operation takes 3 ns and \lstinline {add} operation takes 2 ns. Part a) has a clock period of 1 ns, and one MAC operation takes 5 cycles. Thus the performance is 200 million MACs/sec. Part b) has a clock period of 2 ns, and the MAC takes 3 cycles resulting in approximately 167 million MACs/sec. Part c) has a clock period of 5 ns. By using operation chaining, a MAC operation takes 1 cycle for a clock period of 200 million MACs/sec. \relax }}{37}{figure.caption.18}}
\newlabel{fig:mac}{{2.2}{37}{The performance of multiply accumulate operation changes depending upon the target clock period. Assume the \lstinline {multiply} operation takes 3 ns and \lstinline {add} operation takes 2 ns. Part a) has a clock period of 1 ns, and one MAC operation takes 5 cycles. Thus the performance is 200 million MACs/sec. Part b) has a clock period of 2 ns, and the MAC takes 3 cycles resulting in approximately 167 million MACs/sec. Part c) has a clock period of 5 ns. By using operation chaining, a MAC operation takes 1 cycle for a clock period of 200 million MACs/sec. \relax }{figure.caption.18}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir11\textunderscore ifelse.c}{38}{lstlisting.2.-5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  Removing the conditional statement from the \lstinline {for} loop creates a more efficient hardware implementation. \relax }}{38}{figure.caption.19}}
\newlabel{fig:fir11_ifelse}{{2.3}{38}{Removing the conditional statement from the \lstinline {for} loop creates a more efficient hardware implementation. \relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Code Hoisting}{38}{section.2.6}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir11\textunderscore partition.c}{39}{lstlisting.2.-6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  A code snippet corresponding to splitting the \lstinline {for} loop into two separate loops. \relax }}{39}{figure.caption.20}}
\newlabel{fig:fir11_partition}{{2.4}{39}{A code snippet corresponding to splitting the \lstinline {for} loop into two separate loops. \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Loop Fission}{39}{section.2.7}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir11\textunderscore unrollTDL.c}{40}{lstlisting.2.-7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  Manually unrolling the \lstinline {TDL} loop in the \lstinline {fir11} function. \relax }}{40}{figure.caption.21}}
\newlabel{fig:fir11_unrollTDL}{{2.5}{40}{Manually unrolling the \lstinline {TDL} loop in the \lstinline {fir11} function. \relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Loop Unrolling}{40}{section.2.8}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fir11\textunderscore unrollMAC.c}{42}{lstlisting.2.-8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  Manually unrolling the \lstinline {MAC} loop in the \lstinline {fir11} function by a factor of four. \relax }}{42}{figure.caption.22}}
\newlabel{fig:fir11_unrollMAC}{{2.6}{42}{Manually unrolling the \lstinline {MAC} loop in the \lstinline {fir11} function by a factor of four. \relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Loop Pipelining}{43}{section.2.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Part a) shows a schedule for the body of the \lstinline {MAC for} loop. Part b) shows the schedule for three iterations of a pipelined version of the \lstinline {MAC for} loop.\relax }}{44}{figure.caption.23}}
\newlabel{fig:pipeline_mac}{{2.7}{44}{Part a) shows a schedule for the body of the \lstinline {MAC for} loop. Part b) shows the schedule for three iterations of a pipelined version of the \lstinline {MAC for} loop.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Part a) shows a schedule for two iterations of the body of the \lstinline {TDL for} loop. Part b) shows the schedule for three iterations of a pipelined version of the \lstinline {TDL for} loop with II=1.\relax }}{46}{figure.caption.24}}
\newlabel{fig:pipeline_tdl}{{2.8}{46}{Part a) shows a schedule for two iterations of the body of the \lstinline {TDL for} loop. Part b) shows the schedule for three iterations of a pipelined version of the \lstinline {TDL for} loop with II=1.\relax }{figure.caption.24}{}}
\citation{ug902}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Bitwidth Optimization}{47}{section.2.10}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Complex FIR Filter}{49}{section.2.11}}
\newlabel{eq:complex_fir}{{2.4}{49}{Complex FIR Filter}{equation.2.11.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces A complex FIR filter built from four real FIR filters. The input I and Q samples are feed into four different real FIR filters. The FIR filters hold the in-phase (FIR I) and quadrature (FIR Q) complex coefficients. \relax }}{50}{figure.caption.25}}
\newlabel{fig:complex_fir}{{2.9}{50}{A complex FIR filter built from four real FIR filters. The input I and Q samples are feed into four different real FIR filters. The FIR filters hold the in-phase (FIR I) and quadrature (FIR Q) complex coefficients. \relax }{figure.caption.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/complex\textunderscore fir.cpp}{51}{lstlisting.2.-9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces The Vivado\textsuperscript  {\textregistered } HLS\xspace  code to hierarchically implement a complex FIR filter using four real FIR filters.\relax }}{51}{figure.caption.26}}
\newlabel{fig:complex_fir_code}{{2.10}{51}{The \VHLS code to hierarchically implement a complex FIR filter using four real FIR filters.\relax }{figure.caption.26}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/inline.c}{52}{lstlisting.2.-10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces  A simple and trivial example to demonstrate the \lstinline {inline} directive. The \lstinline {top_function} has four function calls to the function \lstinline {mul}. If we placed an \lstinline {inline} directive on the \lstinline {mul} function, the result is similar to what you see in the function \lstinline {inlined_top_function}. \relax }}{52}{figure.caption.27}}
\newlabel{fig:inline}{{2.11}{52}{A simple and trivial example to demonstrate the \lstinline {inline} directive. The \lstinline {top_function} has four function calls to the function \lstinline {mul}. If we placed an \lstinline {inline} directive on the \lstinline {mul} function, the result is similar to what you see in the function \lstinline {inlined_top_function}. \relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.12}Conclusion}{52}{section.2.12}}
\citation{duprat1993cordic}
\citation{ahmed1982highly}
\citation{andraka1996building}
\citation{despain1974fourier}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}CORDIC}{55}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:cordic}{{3}{55}{CORDIC}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Overview}{55}{section.3.1}}
\newlabel{subsec:CORDIC_Overview}{{3.1}{55}{Overview}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Background}{56}{section.3.2}}
\newlabel{subsec:CORDIC_Basics}{{3.2}{56}{Background}{section.3.2}{}}
\newlabel{eq:rotation_matrix}{{3.1}{56}{Background}{equation.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  Using the CORDIC to calculate the functions $\qopname  \relax o{sin}\phi $ and $\qopname  \relax o{cos}\phi $. Here, the CORDIC starts at the x-axis with a corresponding $0^\circ $ angle. It then performs four iterative positive/negative rotations in increasingly smaller rotation angle with the ultimate goal of reaching the target angle $\phi $. Once we finish our rotations we are close to the target angle. We take the corresponding $x$ and $y$ values of the final vector which correspond to $\qopname  \relax o{cos}\phi $ and $\qopname  \relax o{sin}\phi $ (respectively) assuming the length of the vector is $1$. The key to the CORDIC is doing all of this in a computationally efficient manner. \relax }}{57}{figure.caption.28}}
\newlabel{fig:cordic_overview}{{3.1}{57}{Using the CORDIC to calculate the functions $\sin \phi $ and $\cos \phi $. Here, the CORDIC starts at the x-axis with a corresponding $0^\circ $ angle. It then performs four iterative positive/negative rotations in increasingly smaller rotation angle with the ultimate goal of reaching the target angle $\phi $. Once we finish our rotations we are close to the target angle. We take the corresponding $x$ and $y$ values of the final vector which correspond to $\cos \phi $ and $\sin \phi $ (respectively) assuming the length of the vector is $1$. The key to the CORDIC is doing all of this in a computationally efficient manner. \relax }{figure.caption.28}{}}
\newlabel{eq:cordicgain}{{3.26}{60}{Background}{equation.3.2.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The rotating angle, scaling factor, and CORDIC gain for the first seven iterations of a CORDIC. Note that the angle decreases by approximately half each time. The scaling factor indicates how much the length the the vector increases during that rotation. The CORDIC gain is the overall increase in the length of the vector which is the product of all of the scaling factors for the current and previous rotations.\relax }}{61}{table.caption.29}}
\newlabel{table:cordic}{{3.1}{61}{The rotating angle, scaling factor, and CORDIC gain for the first seven iterations of a CORDIC. Note that the angle decreases by approximately half each time. The scaling factor indicates how much the length the the vector increases during that rotation. The CORDIC gain is the overall increase in the length of the vector which is the product of all of the scaling factors for the current and previous rotations.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Calculating Sine and Cosine}{61}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Calculating $\qopname  \relax o{cos}60^{\circ }$ and $\qopname  \relax o{sin}60^{\circ }$ using the CORDIC algorithm. Five rotations are performed using incrementally larger $i$ values (0,1,2,3,4). The result is a vector with an angle of $61.078^{\circ }$. The corresponding $x$ and $y$ values of that vector give the approximate desired cosine and sine values. \relax }}{62}{figure.caption.30}}
\newlabel{fig:cordic_rotations}{{3.2}{62}{Calculating $\cos 60^{\circ }$ and $\sin 60^{\circ }$ using the CORDIC algorithm. Five rotations are performed using incrementally larger $i$ values (0,1,2,3,4). The result is a vector with an angle of $61.078^{\circ }$. The corresponding $x$ and $y$ values of that vector give the approximate desired cosine and sine values. \relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Cartesian to Polar Conversion}{63}{section.3.4}}
\@writefile{lol}{\contentsline {lstlisting}{examples/cordic.c}{64}{lstlisting.3.-11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces CORDIC code implementing the sine and cosine of a given angle.\relax }}{64}{figure.caption.31}}
\newlabel{fig:cordic_code}{{3.3}{64}{CORDIC code implementing the sine and cosine of a given angle.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces  The figure shows a two-dimensional plane and a vector represented in both the Cartesian form $(x,y)$ and the polar form $(r, \theta )$ and provides the relationship between those two coordinate systems. \relax }}{65}{figure.caption.32}}
\newlabel{fig:cordic_polar}{{3.4}{65}{The figure shows a two-dimensional plane and a vector represented in both the Cartesian form $(x,y)$ and the polar form $(r, \theta )$ and provides the relationship between those two coordinate systems. \relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Number Representation}{66}{section.3.5}}
\newlabel{sec:number_representation}{{3.5}{66}{Number Representation}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Binary and Hexadecimal Numbers}{66}{subsection.3.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The first step in performing a Cartesian to polar conversion is to perform a rotation by $\pm 90^{\circ }$ in order to get the initial vector into either Quadrant I or IV. Once it is in either of these two quadrants, subsequent rotations will allow the vector to reach a final angle of $0^{\circ }$. At this point, the radial value of the initial vector is the $x$ value of the final rotated vector and the phase of the initial vector is the summation of all the angles that the CORDIC performed. Parts a) and b) show an example with the initial $y$ value is positive, which means that the vector resides in either Quadrant I or II. Rotating by $-90^{\circ }$ puts them into the appropriate quadrant. Parts c) and d) show a similar situation when the $y$ value of the initial vector is negative. Here we wish to rotate by $90^{\circ }$ to get the vector into Quadrant I or IV. \relax }}{67}{figure.caption.33}}
\newlabel{fig:rotate90}{{3.5}{67}{The first step in performing a Cartesian to polar conversion is to perform a rotation by $\pm 90^{\circ }$ in order to get the initial vector into either Quadrant I or IV. Once it is in either of these two quadrants, subsequent rotations will allow the vector to reach a final angle of $0^{\circ }$. At this point, the radial value of the initial vector is the $x$ value of the final rotated vector and the phase of the initial vector is the summation of all the angles that the CORDIC performed. Parts a) and b) show an example with the initial $y$ value is positive, which means that the vector resides in either Quadrant I or II. Rotating by $-90^{\circ }$ puts them into the appropriate quadrant. Parts c) and d) show a similar situation when the $y$ value of the initial vector is negative. Here we wish to rotate by $90^{\circ }$ to get the vector into Quadrant I or IV. \relax }{figure.caption.33}{}}
\citation{systemc}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Negative numbers}{69}{subsection.3.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Overflow, Underflow, and Rounding}{70}{subsection.3.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Binary arithmetic}{72}{subsection.3.5.4}}
\newlabel{sec:arithmetic}{{3.5.4}{72}{Binary arithmetic}{subsection.3.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Representing Arbitrary Precision Integers in C and C++}{73}{subsection.3.5.5}}
\newlabel{sec:arbitrary_precision}{{3.5.5}{73}{Representing Arbitrary Precision Integers in C and C++}{subsection.3.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.6}Floating Point}{75}{subsection.3.5.6}}
\newlabel{sec:floating_point}{{3.5.6}{75}{Floating Point}{subsection.3.5.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Further Optimizations}{75}{section.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Conclusion}{76}{section.3.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Discrete Fourier Transform}{77}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:dft}{{4}{77}{Discrete Fourier Transform}{chapter.4}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{main}{dftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@gls@reference{main}{fftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Fourier Series}{77}{section.4.1}}
\newlabel{eq:fourier_series}{{4.1}{77}{Fourier Series}{equation.4.1.1}{}}
\newlabel{eq:fourier_coefficients}{{4.2}{78}{Fourier Series}{equation.4.1.2}{}}
\newlabel{eq:cos_exp}{{4.10}{79}{Fourier Series}{equation.4.1.10}{}}
\newlabel{eq:sin_exp}{{4.11}{79}{Fourier Series}{equation.4.1.11}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{79}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}\gls {dft} Background}{79}{section.4.2}}
\newlabel{sec:DFTbackground}{{4.2}{79}{\gls {dft} Background}{section.4.2}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{79}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{79}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{79}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{79}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A visualization of the relationship between the cosine, sine, and the complex exponential. Part a) shows the sum of two complex vectors, $e^{jx}$ and $e^{-jx}$. The result of this summation lands exactly on the real axis with the value $2 \qopname  \relax o{cos}(x)$. Part b) shows a similar summation except this time summing the vectors $e^{jx}$ and $-e^{-jx}$. This summation lands on the imaginary axis with the value $2 \qopname  \relax o{sin}(x)$.\relax }}{80}{figure.caption.34}}
\newlabel{fig:sin_cos_exp}{{4.1}{80}{A visualization of the relationship between the cosine, sine, and the complex exponential. Part a) shows the sum of two complex vectors, $e^{jx}$ and $e^{-jx}$. The result of this summation lands exactly on the real axis with the value $2 \cos (x)$. Part b) shows a similar summation except this time summing the vectors $e^{jx}$ and $-e^{-jx}$. This summation lands on the imaginary axis with the value $2 \sin (x)$.\relax }{figure.caption.34}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{80}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces  A real valued discrete function $g[ ]$ in the time domain with $N$ points has a frequency domain representation with $N/2 + 1$ samples. Each of these frequency domain samples has one cosine and one sine amplitude value. Collectively these two amplitude values can be represented by a complex number with the cosine amplitude representing the real part and the sine amplitude the imaginary part. \relax }}{81}{figure.caption.35}}
\newlabel{fig:basic-DFT}{{4.2}{81}{A real valued discrete function $g[ ]$ in the time domain with $N$ points has a frequency domain representation with $N/2 + 1$ samples. Each of these frequency domain samples has one cosine and one sine amplitude value. Collectively these two amplitude values can be represented by a complex number with the cosine amplitude representing the real part and the sine amplitude the imaginary part. \relax }{figure.caption.35}{}}
\newlabel{eq:Smatrix}{{4.12}{81}{\gls {dft} Background}{equation.4.2.12}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{81}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{81}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{81}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{81}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces  The elements of the $S$ shown as a complex vectors. \relax }}{82}{figure.caption.36}}
\newlabel{fig:dft_visualization}{{4.3}{82}{The elements of the $S$ shown as a complex vectors. \relax }{figure.caption.36}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/matrix\textunderscore vector\textunderscore base.c}{82}{lstlisting.4.-19}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Simple code implementing a matrix-vector multiplication.\relax }}{82}{figure.caption.37}}
\newlabel{fig:matrix_vector_base}{{4.4}{82}{Simple code implementing a matrix-vector multiplication.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Matrix-Vector Multiplication Optimizations}{82}{section.4.3}}
\newlabel{subsec:mvmul_implementation}{{4.3}{82}{Matrix-Vector Multiplication Optimizations}{section.4.3}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{81}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{82}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{82}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A possible implementation of matrix-vector multiplication from the code in Figure \ref  {fig:matrix_vector_base}.\relax }}{83}{figure.caption.38}}
\newlabel{fig:matrix_vector_sequential}{{4.5}{83}{A possible implementation of matrix-vector multiplication from the code in Figure \ref {fig:matrix_vector_base}.\relax }{figure.caption.38}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{82}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{82}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{83}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{83}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Pipelining and Parallelism}{83}{section.4.4}}
\@writefile{lol}{\contentsline {lstlisting}{examples/matrix\textunderscore vector\textunderscore base\textunderscore unroll\textunderscore inner.c}{84}{lstlisting.4.-20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The matrix-vector multiplication example with a manually unrolled inner loop.\relax }}{84}{figure.caption.39}}
\newlabel{fig:matrix_vector_base_unroll_inner}{{4.6}{84}{The matrix-vector multiplication example with a manually unrolled inner loop.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces A data flow graph of the expression resulting from the unrolled inner loop from Figure \ref  {fig:matrix_vector_base_unroll_inner}.\relax }}{85}{figure.caption.40}}
\newlabel{fig:matrix_vector_unroll_inner_dfg}{{4.7}{85}{A data flow graph of the expression resulting from the unrolled inner loop from Figure \ref {fig:matrix_vector_base_unroll_inner}.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Possible sequential implementations resulting from the unrolled inner loop from Figure \ref  {fig:matrix_vector_base_unroll_inner}.\relax }}{85}{figure.caption.41}}
\newlabel{fig:dft_behavior1}{{4.8}{85}{Possible sequential implementations resulting from the unrolled inner loop from Figure \ref {fig:matrix_vector_base_unroll_inner}.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Possible pipelined implementations resulting from the unrolled inner loop from Figure \ref  {fig:matrix_vector_base_unroll_inner}.\relax }}{86}{figure.caption.42}}
\newlabel{fig:dft_behavior2}{{4.9}{86}{Possible pipelined implementations resulting from the unrolled inner loop from Figure \ref {fig:matrix_vector_base_unroll_inner}.\relax }{figure.caption.42}{}}
\@gls@reference{main}{looppipelining}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{84}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Possible implementations resulting from the unrolled inner loop from Figure \ref  {fig:matrix_vector_base_unroll_inner} using pipelined multipliers.\relax }}{87}{figure.caption.43}}
\newlabel{fig:dft_behavior_pipelined}{{4.10}{87}{Possible implementations resulting from the unrolled inner loop from Figure \ref {fig:matrix_vector_base_unroll_inner} using pipelined multipliers.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Storage Tradeoffs and Array Partitioning}{87}{section.4.5}}
\newlabel{subsec:dft_array_partitioning}{{4.5}{87}{Storage Tradeoffs and Array Partitioning}{section.4.5}{}}
\@gls@reference{main}{arraypartitioning}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{87}}
\@writefile{lol}{\contentsline {lstlisting}{examples/matrix\textunderscore vector\textunderscore optimized.c}{89}{lstlisting.4.-21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Matrix-vector multiplication with a particular choice of array partitioning and pipelining. \relax }}{89}{figure.caption.44}}
\newlabel{fig:matrix_vector_optimized}{{4.11}{89}{Matrix-vector multiplication with a particular choice of array partitioning and pipelining. \relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Matrix-vector multiplication architecture with a particular choice of array partitioning and pipelining. The pipelining registers have been elided and the behavior is shown at right.\relax }}{89}{figure.caption.45}}
\newlabel{fig:matrix_vector_optimized_behavior}{{4.12}{89}{Matrix-vector multiplication architecture with a particular choice of array partitioning and pipelining. The pipelining registers have been elided and the behavior is shown at right.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Matrix-vector multiplication architectures at II=3 with a particular choices of array partitioning. On the left, the arrays have been partitioned more than necessary, resulting in multiplexers. On the right, the arrays are partitioned with factor=3. In this case, multiplexing has been reduced, but the \lstinline |j| loop index becomes a part of the address computations.\relax }}{90}{figure.caption.46}}
\newlabel{fig:matrix_vector_partition_factor}{{4.13}{90}{Matrix-vector multiplication architectures at II=3 with a particular choices of array partitioning. On the left, the arrays have been partitioned more than necessary, resulting in multiplexers. On the right, the arrays are partitioned with factor=3. In this case, multiplexing has been reduced, but the \lstinline |j| loop index becomes a part of the address computations.\relax }{figure.caption.46}{}}
\@gls@reference{main}{partial_loop_unrolling}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{90}}
\@writefile{lol}{\contentsline {lstlisting}{examples/matrix\textunderscore vector\textunderscore unroll\textunderscore inner2.c}{91}{lstlisting.4.-22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces The inner loop of matrix-vector multiply manually unrolled by a factor of two. \relax }}{91}{figure.caption.47}}
\newlabel{fig:matrix_vector_unroll_inner2}{{4.14}{91}{The inner loop of matrix-vector multiply manually unrolled by a factor of two. \relax }{figure.caption.47}{}}
\citation{detrey07hotbm}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Baseline Implementation}{92}{section.4.6}}
\newlabel{subsec:dft_implementation}{{4.6}{92}{Baseline Implementation}{section.4.6}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\@writefile{lol}{\contentsline {lstlisting}{examples/dft.c}{93}{lstlisting.4.-23}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Baseline code for the \gls {dft}.\relax }}{93}{figure.caption.48}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\newlabel{fig:dft_code}{{4.15}{93}{Baseline code for the \gls {dft}.\relax }{figure.caption.48}{}}
\citation{lee87sdfArchitecture}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}\gls {dft} optimization}{94}{section.4.7}}
\newlabel{subsec:dft_optimization}{{4.7}{94}{\gls {dft} optimization}{section.4.7}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@gls@reference{main}{recurrence}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@gls@reference{main}{loopinterchange}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{94}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces  A high level architectural diagram of the \gls {dft} as specified in the code from Figure \ref  {fig:dft_code}. This is not a comprehensive view of the architecture, e.g., it is missing components related to updating the loop counters \lstinline |i| and \lstinline |j|. It is meant to provide an approximate notion of how this architecture will be synthesized. Here we've assumed that floating point operators take 4 clock cycles.\relax }}{95}{figure.caption.49}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{92}}
\newlabel{fig:dft_sequential_arch}{{4.16}{95}{A high level architectural diagram of the \gls {dft} as specified in the code from Figure \ref {fig:dft_code}. This is not a comprehensive view of the architecture, e.g., it is missing components related to updating the loop counters \lstinline |i| and \lstinline |j|. It is meant to provide an approximate notion of how this architecture will be synthesized. Here we've assumed that floating point operators take 4 clock cycles.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Pipelined version of the behavior in Figure \ref  {fig:dft_sequential_arch}. In this case, the initiation interval of the loop is limited to 4, since each floating point addition takes 4 clock cycles to complete and the result is required before the next loop iteration begins (the dependence shown in red). The dependencies for all iterations are summarized in the diagram on the right.\relax }}{96}{figure.caption.50}}
\newlabel{fig:dft_recurrence_behavior}{{4.17}{96}{Pipelined version of the behavior in Figure \ref {fig:dft_sequential_arch}. In this case, the initiation interval of the loop is limited to 4, since each floating point addition takes 4 clock cycles to complete and the result is required before the next loop iteration begins (the dependence shown in red). The dependencies for all iterations are summarized in the diagram on the right.\relax }{figure.caption.50}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{96}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{96}}
\newlabel{eq:1DS}{{4.14}{96}{\gls {dft} optimization}{equation.4.7.14}{}}
\@gls@reference{acronym}{rom}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{96}}
\@gls@reference{main}{romg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{96}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Conclusion}{97}{section.4.8}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{97}}
\citation{CLR}
\citation{cooley65}
\citation{heideman84}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Fast Fourier Transform}{99}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:fft}{{5}{99}{Fast Fourier Transform}{chapter.5}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{main}{dftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{main}{fftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Background}{99}{section.5.1}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\citation{gentleman1966fast}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{99}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\newlabel{eq:2ptlower}{{5.3}{100}{Background}{equation.5.1.3}{}}
\newlabel{eq:2pthigher}{{5.4}{100}{Background}{equation.5.1.4}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Part a) is a data flow graph for a 2 point \gls {dft}/\gls {fft}. Part b) shows the same computation, but viewed as a butterfly structure. This is a common representation for the computation of an \gls {fft} in the digital signal processing domain.\relax }}{101}{figure.caption.51}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\newlabel{fig:2pointFFT}{{5.1}{101}{Part a) is a data flow graph for a 2 point \gls {dft}/\gls {fft}. Part b) shows the same computation, but viewed as a butterfly structure. This is a common representation for the computation of an \gls {fft} in the digital signal processing domain.\relax }{figure.caption.51}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{100}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\newlabel{eq:reduced4point}{{5.12}{102}{Background}{equation.5.1.12}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A four point \gls {fft} divided into two stages. Stage 1 has uses two 2 point \gls {fft}s -- one 2 point \gls {fft} for the even input values and the other 2 point \gls {fft} for the odd input values. Stage 2 performs the remaining operations to complete the \gls {fft} computation as detailed in Equation \ref  {eq:reduced4point}. \relax }}{103}{figure.caption.52}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\newlabel{fig:4ptFFT}{{5.2}{103}{A four point \gls {fft} divided into two stages. Stage 1 has uses two 2 point \gls {fft}s -- one 2 point \gls {fft} for the even input values and the other 2 point \gls {fft} for the odd input values. Stage 2 performs the remaining operations to complete the \gls {fft} computation as detailed in Equation \ref {eq:reduced4point}. \relax }{figure.caption.52}{}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{102}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{103}}
\newlabel{eq:fft-full}{{5.13}{103}{Background}{equation.5.1.13}{}}
\newlabel{eq:fft-split}{{5.14}{103}{Background}{equation.5.1.14}{}}
\newlabel{eq:fft-split-2}{{5.15}{103}{Background}{equation.5.1.15}{}}
\newlabel{eq:fft-split-3}{{5.16}{104}{Background}{equation.5.1.16}{}}
\newlabel{eq:fft-split-4}{{5.17}{104}{Background}{equation.5.1.17}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{104}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{104}}
\newlabel{eq:fft-upper}{{5.18}{104}{Background}{equation.5.1.18}{}}
\newlabel{eq:fft-split-3-upper}{{5.19}{104}{Background}{equation.5.1.19}{}}
\newlabel{eq:fft-split-4-upper}{{5.20}{104}{Background}{equation.5.1.20}{}}
\newlabel{eq:fft-split-5-upper}{{5.21}{104}{Background}{equation.5.1.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Building an $N$ point \gls {fft} from two $N/2$ point \gls {fft}s. The upper $N/2$ point \gls {fft} is performed on the even inputs; the lower $N/2$ \gls {fft} uses the odd inputs. \relax }}{105}{figure.caption.53}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\newlabel{fig:NptFFT}{{5.3}{105}{Building an $N$ point \gls {fft} from two $N/2$ point \gls {fft}s. The upper $N/2$ point \gls {fft} is performed on the even inputs; the lower $N/2$ \gls {fft} uses the odd inputs. \relax }{figure.caption.53}{}}
\newlabel{eq:fft-split-6-upper}{{5.22}{105}{Background}{equation.5.1.22}{}}
\newlabel{eq:fft-split-7-upper}{{5.23}{105}{Background}{equation.5.1.23}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces An 8 point \gls {fft} built recursively. There are two 4 point \gls {fft}s, which each use two 2 point \gls {fft}s. The inputs must be reordered to even and odd elements twice. This results in reordering based upon the bit reversal of the indices.\relax }}{106}{figure.caption.54}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\newlabel{fig:8ptFFT}{{5.4}{106}{An 8 point \gls {fft} built recursively. There are two 4 point \gls {fft}s, which each use two 2 point \gls {fft}s. The inputs must be reordered to even and odd elements twice. This results in reordering based upon the bit reversal of the indices.\relax }{figure.caption.54}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{105}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces The index, three bit binary value for that index, bit reversed binary value, and the resulting bit reversed index.\relax }}{107}{table.caption.55}}
\newlabel{table:bit_reverse}{{5.1}{107}{The index, three bit binary value for that index, bit reversed binary value, and the resulting bit reversed index.\relax }{table.caption.55}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\citation{cooley65}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{107}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Baseline Implementation}{108}{section.5.2}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{108}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fft\textunderscore sw.c}{110}{lstlisting.5.-24}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces  A common implementation for the \gls {fft} using three nested \lstinline |for| loops. While this may work well running as software on a processor, it is far from optimal for a hardware implementation.\relax }}{110}{figure.caption.56}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{109}}
\newlabel{fig:fft_sw}{{5.5}{110}{A common implementation for the \gls {fft} using three nested \lstinline |for| loops. While this may work well running as software on a processor, it is far from optimal for a hardware implementation.\relax }{figure.caption.56}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{111}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{111}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{111}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Bit Reversal}{111}{section.5.3}}
\newlabel{sec:fft_bit_reversal}{{5.3}{111}{Bit Reversal}{section.5.3}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{111}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fft\textunderscore bit\textunderscore reverse.c}{112}{lstlisting.5.-25}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces  The first stage in our \gls {fft} implementation reorders the input data. This is done by swapping the value at index $i$ in the input array with the value at the bit reversed index corresponding to $i$. The function \lstinline |reverse_bits| gives the bit reversed value corresponding to the \lstinline |input| argument. And the function \lstinline |bit_reverse| swaps the values in the input array. \relax }}{112}{figure.caption.57}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{111}}
\newlabel{fig:fft_bit_reverse}{{5.6}{112}{The first stage in our \gls {fft} implementation reorders the input data. This is done by swapping the value at index $i$ in the input array with the value at the bit reversed index corresponding to $i$. The function \lstinline |reverse_bits| gives the bit reversed value corresponding to the \lstinline |input| argument. And the function \lstinline |bit_reverse| swaps the values in the input array. \relax }{figure.caption.57}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/fft\textunderscore stages.cpp}{113}{lstlisting.5.-26}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces  The code divides an 8 point \gls {fft} into four stages, each of which is a separate function. The \lstinline {bit_reverse} function is the first stages. And there are three stages for the 8 point \gls {fft}. \relax }}{113}{figure.caption.58}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\newlabel{fig:fft_stages_code}{{5.7}{113}{The code divides an 8 point \gls {fft} into four stages, each of which is a separate function. The \lstinline {bit_reverse} function is the first stages. And there are three stages for the 8 point \gls {fft}. \relax }{figure.caption.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Task Pipelining}{113}{section.5.4}}
\newlabel{sec:fft_task_pipelining}{{5.4}{113}{Task Pipelining}{section.5.4}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@gls@reference{main}{taskpipelining}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces  Dividing the \gls {fft} into different stages allows for task pipelining across each of these stages. The figure shows an example with three \gls {fft} stages (i.e., an 8 point \gls {fft}). The figure shows four 8 point \gls {fft} executing at the same time. \relax }}{114}{figure.caption.59}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\newlabel{fig:fftstages}{{5.8}{114}{Dividing the \gls {fft} into different stages allows for task pipelining across each of these stages. The figure shows an example with three \gls {fft} stages (i.e., an 8 point \gls {fft}). The figure shows four 8 point \gls {fft} executing at the same time. \relax }{figure.caption.59}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{113}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{main}{taskpipelining}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{main}{process}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{114}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Conclusion}{116}{section.5.5}}
\newlabel{sec:fft_conclusion}{{5.5}{116}{Conclusion}{section.5.5}{}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@gls@reference{acronym}{fft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{116}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Sparse Matrix Vector Multiplication}{117}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:spmv}{{6}{117}{Sparse Matrix Vector Multiplication}{chapter.6}{}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{main}{crsg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Background}{117}{section.6.1}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces A $4 \times 4$ matrix $\mathbf  {M}$ represented in two different ways: as a `dense' matrix stored in a two-dimensional array, and as a sparse matrix stored in the compressed row storage (\gls {crs}) form, a data structure consisting of three arrays. \relax }}{118}{figure.caption.60}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\newlabel{fig:crs}{{6.1}{118}{A $4 \times 4$ matrix $\mathbf {M}$ represented in two different ways: as a `dense' matrix stored in a two-dimensional array, and as a sparse matrix stored in the compressed row storage (\gls {crs}) form, a data structure consisting of three arrays. \relax }{figure.caption.60}{}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{117}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{118}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{118}}
\@writefile{lol}{\contentsline {lstlisting}{examples/spmv.cpp}{119}{lstlisting.6.-27}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces  The baseline code for sparse matrix vector (SpMV) multiplication, which performs the operation $y = \mathbf  {M} \cdot x$. The variables \lstinline {rowPtr}, \lstinline {columnIndex}, and \lstinline {values} hold $\mathbf  {M}$ in \gls {crs} format. The first \lstinline {for} loop iterates across the rows while the second nested \lstinline {for} loop iterates across the columns of $\mathbf  {M}$ by multiplying each non-zero element by the corresponding element in the vector \lstinline {x} which results in one element in the resulting vector \lstinline {y}. \relax }}{119}{figure.caption.61}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{119}}
\newlabel{fig:spmv_arch1}{{6.2}{119}{The baseline code for sparse matrix vector (SpMV) multiplication, which performs the operation $y = \mathbf {M} \cdot x$. The variables \lstinline {rowPtr}, \lstinline {columnIndex}, and \lstinline {values} hold $\mathbf {M}$ in \gls {crs} format. The first \lstinline {for} loop iterates across the rows while the second nested \lstinline {for} loop iterates across the columns of $\mathbf {M}$ by multiplying each non-zero element by the corresponding element in the vector \lstinline {x} which results in one element in the resulting vector \lstinline {y}. \relax }{figure.caption.61}{}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{119}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{119}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{119}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Baseline Implementation}{119}{section.6.2}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{119}}
\@writefile{lol}{\contentsline {lstlisting}{examples/spmv.h}{120}{lstlisting.6.-28}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces  The header file for \lstinline {spmv} function and testbench. \relax }}{120}{figure.caption.62}}
\newlabel{fig:spmv.h}{{6.3}{120}{The header file for \lstinline {spmv} function and testbench. \relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Testbench}{120}{section.6.3}}
\@gls@reference{acronym}{crs}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{120}}
\@writefile{lol}{\contentsline {lstlisting}{examples/spmv\textendash top.cpp}{121}{lstlisting.6.-29}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces  A simple testbench for our \lstinline {spmv} function. The testbench generates one example and computes the matrix vector multiplication using a sparse (\lstinline {spmv}) and non-sparse function (\lstinline {matrixvector}).\relax }}{121}{figure.caption.63}}
\newlabel{fig:spmv_test}{{6.4}{121}{A simple testbench for our \lstinline {spmv} function. The testbench generates one example and computes the matrix vector multiplication using a sparse (\lstinline {spmv}) and non-sparse function (\lstinline {matrixvector}).\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Specifying Loop Properties}{122}{section.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}C/RTL Cosimulation}{123}{section.6.5}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{123}}
\@gls@reference{main}{rtlg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{123}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Architecture and behavior of the \lstinline {spmv} code with a pipelined inner loop.\relax }}{124}{figure.caption.64}}
\newlabel{fig:spmv_pipeline_inner}{{6.5}{124}{Architecture and behavior of the \lstinline {spmv} code with a pipelined inner loop.\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Loop Optimizations and Array Partitioning}{124}{section.6.6}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Potential optimizations for sparse matrix-vector multiplication. \relax }}{125}{table.caption.65}}
\newlabel{table:spmv_optimizations}{{6.1}{125}{Potential optimizations for sparse matrix-vector multiplication. \relax }{table.caption.65}{}}
\@gls@reference{main}{partial_loop_unrolling}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{126}}
\@writefile{lol}{\contentsline {lstlisting}{examples/spmv\textunderscore unrolled.cpp}{127}{lstlisting.6.-30}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces A partially unrolled version of the \lstinline |spmv| code from Figure \ref  {fig:spmv_arch1}.\relax }}{127}{figure.caption.66}}
\newlabel{fig:spmv_unrolled}{{6.6}{127}{A partially unrolled version of the \lstinline |spmv| code from Figure \ref {fig:spmv_arch1}.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Two different partially unrolled versions of an accumulation. The version on the left has a recurrence with three additions, whereas the version on right only has one addition in the recurrence.\relax }}{127}{figure.caption.67}}
\newlabel{fig:spmv_partial_unroll}{{6.7}{127}{Two different partially unrolled versions of an accumulation. The version on the left has a recurrence with three additions, whereas the version on right only has one addition in the recurrence.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Architecture and behavior of the \lstinline {spmv} code based on the partially unrolled and pipelined inner loop shown in Figure \ref  {fig:spmv_unrolled}.\relax }}{128}{figure.caption.68}}
\newlabel{fig:spmv_unrolled_behavior}{{6.8}{128}{Architecture and behavior of the \lstinline {spmv} code based on the partially unrolled and pipelined inner loop shown in Figure \ref {fig:spmv_unrolled}.\relax }{figure.caption.68}{}}
\@gls@reference{main}{cosimulation}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{128}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{128}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Conclusion}{128}{section.6.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Matrix Multiplication}{129}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:matrix_multiplication}{{7}{129}{Matrix Multiplication}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Background}{129}{section.7.1}}
\newlabel{eq:ABmatrix}{{7.3}{129}{Background}{equation.7.1.3}{}}
\newlabel{eq:ABmatrix_product}{{7.4}{129}{Background}{equation.7.1.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/matrixmultiplication.cpp}{130}{lstlisting.7.-31}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces A common three \lstinline {for} loop structure for matrix multiplication. The outer \lstinline {for} loops, labeled \lstinline {rows} and \lstinline {cols}, iterate across the rows and columns of the output matrix $\mathbf  {AB}$. The innermost loop, labeled \lstinline {product} multiplies the appropriate elements of one row of $\mathbf  {A}$ and one column of $\mathbf  {B}$ and accumulates them until it has the result for the element in $\mathbf  {AB}$ . \relax }}{130}{figure.caption.69}}
\newlabel{fig:matrixmultiplication_sw}{{7.1}{130}{A common three \lstinline {for} loop structure for matrix multiplication. The outer \lstinline {for} loops, labeled \lstinline {rows} and \lstinline {cols}, iterate across the rows and columns of the output matrix $\mathbf {AB}$. The innermost loop, labeled \lstinline {product} multiplies the appropriate elements of one row of $\mathbf {A}$ and one column of $\mathbf {B}$ and accumulates them until it has the result for the element in $\mathbf {AB}$ . \relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Complete Matrix Multiplication}{130}{section.7.2}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{131}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{131}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{131}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{131}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{131}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Three different implementations of a two-dimensional array. On the left is the original array consisting of $N*M$ elements. In the middle, the array has been transformed using the \lstinline {array_partition} directive, resulting in $M$ memories, each with $N$ elements. On the right, the array has been transformed using the \lstinline {array_reshape} directive, resulting in one memory with $N$ locations and each location contains $M$ elements of the original array.\relax }}{132}{figure.caption.70}}
\newlabel{fig:matmul_array_reshape}{{7.2}{132}{Three different implementations of a two-dimensional array. On the left is the original array consisting of $N*M$ elements. In the middle, the array has been transformed using the \lstinline {array_partition} directive, resulting in $M$ memories, each with $N$ elements. On the right, the array has been transformed using the \lstinline {array_reshape} directive, resulting in one memory with $N$ locations and each location contains $M$ elements of the original array.\relax }{figure.caption.70}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Block Matrix Multiplication}{133}{section.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces  One possible blocked decomposition of the matrix multiplication of two $4 \times 4$ matrices. The entire $\mathbf  {AB}$ product is decomposed into four matrix multiply operations operating on a $2 \times 4$ block of $\mathbf  {A}$ and a $4 \times 2$ block of $\mathbf  {B}$.\relax }}{135}{figure.caption.71}}
\newlabel{fig:blockmm}{{7.3}{135}{One possible blocked decomposition of the matrix multiplication of two $4 \times 4$ matrices. The entire $\mathbf {AB}$ product is decomposed into four matrix multiply operations operating on a $2 \times 4$ block of $\mathbf {A}$ and a $4 \times 2$ block of $\mathbf {B}$.\relax }{figure.caption.71}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/block\textunderscore mm.h}{136}{lstlisting.7.-32}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces  The header file for the block matrix multiplication architecture. The file defines the data types used within the function, the key constants, and the \lstinline {blockmatmul} function interface. \relax }}{136}{figure.caption.72}}
\newlabel{fig:block_mm_h}{{7.4}{136}{The header file for the block matrix multiplication architecture. The file defines the data types used within the function, the key constants, and the \lstinline {blockmatmul} function interface. \relax }{figure.caption.72}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/block\textunderscore mm.cpp}{138}{lstlisting.7.-33}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces  The \lstinline {blockmatmul} function takes a \lstinline {BLOCK_SIZE} set of rows from $\mathbf  {A}$ matrix, a \lstinline {BLOCK_SIZE} set of columns from the $\mathbf  {B}$ matrix, and creates a \lstinline {BLOCK_SIZE} $\times $ \lstinline {BLOCK_SIZE} partial result for the $\mathbf  {AB}$ matrix. The first part of the code (denoted by the label \lstinline {loadA}) stores the rows from $\mathbf  {A}$ into a local memory, the second part in the nested \lstinline {partialsum for} performs the computation for the partial results, and the final part (with the \lstinline {writeoutput} label) takes these results and puts them the proper form to return from the function.\relax }}{138}{figure.caption.73}}
\newlabel{fig:block_mm}{{7.5}{138}{The \lstinline {blockmatmul} function takes a \lstinline {BLOCK_SIZE} set of rows from $\mathbf {A}$ matrix, a \lstinline {BLOCK_SIZE} set of columns from the $\mathbf {B}$ matrix, and creates a \lstinline {BLOCK_SIZE} $\times $ \lstinline {BLOCK_SIZE} partial result for the $\mathbf {AB}$ matrix. The first part of the code (denoted by the label \lstinline {loadA}) stores the rows from $\mathbf {A}$ into a local memory, the second part in the nested \lstinline {partialsum for} performs the computation for the partial results, and the final part (with the \lstinline {writeoutput} label) takes these results and puts them the proper form to return from the function.\relax }{figure.caption.73}{}}
\newlabel{eq:interval}{{7.5}{140}{Block Matrix Multiplication}{equation.7.3.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/blockmatmul\textunderscore test\textunderscore init.cpp}{142}{lstlisting.7.-34}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces  The first part of the testbench for block matrix multiplication. The function is split across two figures since it is too long to display on one page. The rest of the testbench is in Figure \ref  {fig:block_mm_final}. This has a ``software'' version of matrix multiplication, and variable declarations and initializations. \relax }}{142}{figure.caption.74}}
\newlabel{fig:block_mm_init}{{7.6}{142}{The first part of the testbench for block matrix multiplication. The function is split across two figures since it is too long to display on one page. The rest of the testbench is in Figure \ref {fig:block_mm_final}. This has a ``software'' version of matrix multiplication, and variable declarations and initializations. \relax }{figure.caption.74}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/blockmatmul\textunderscore test.cpp}{143}{lstlisting.7.-35}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces  The second portion of the block matrix multiply testbench. The first part is shown in Figure \ref  {fig:block_mm_init}. This shows the computation required to stream the data to the \lstinline {blockmatmul} function, and the code that tests that this function matches a simpler three \lstinline {for} loop implementation. \relax }}{143}{figure.caption.75}}
\newlabel{fig:block_mm_final}{{7.7}{143}{The second portion of the block matrix multiply testbench. The first part is shown in Figure \ref {fig:block_mm_init}. This shows the computation required to stream the data to the \lstinline {blockmatmul} function, and the code that tests that this function matches a simpler three \lstinline {for} loop implementation. \relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Conclusion}{144}{section.7.4}}
\citation{blelloch1990prefix}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Prefix Sum and Histogram}{145}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:prefixsum}{{8}{145}{Prefix Sum and Histogram}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Prefix Sum}{145}{section.8.1}}
\newlabel{sec:prefixSum}{{8.1}{145}{Prefix Sum}{section.8.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/prefixsumBO.cpp}{146}{lstlisting.8.-36}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces  Code for implementing prefix sum, and its accompanying behavior. \relax }}{146}{figure.caption.76}}
\newlabel{fig:prefixsumSW}{{8.1}{146}{Code for implementing prefix sum, and its accompanying behavior. \relax }{figure.caption.76}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/prefixsum\textunderscore optimized.cpp}{146}{lstlisting.8.-37}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces  Code for implementing an optimized prefix sum, and its accompanying behavior. \relax }}{146}{figure.caption.77}}
\newlabel{fig:prefixsum_optimized}{{8.2}{146}{Code for implementing an optimized prefix sum, and its accompanying behavior. \relax }{figure.caption.77}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/prefixsum\textunderscore unrolled.cpp}{147}{lstlisting.8.-38}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces  Optimizing the prefixsum code using \lstinline {unroll}, \lstinline {pipeline}, and \lstinline {array_partition} directives. \relax }}{147}{figure.caption.78}}
\newlabel{fig:prefixsum_unrolled}{{8.3}{147}{Optimizing the prefixsum code using \lstinline {unroll}, \lstinline {pipeline}, and \lstinline {array_partition} directives. \relax }{figure.caption.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces  Part a) displays an architecture corresponding to the code in Figure\nobreakspace  {}\ref  {fig:prefixsumSW}. The dependence on the \lstinline {out[]} array can prevent achieving a loop II of 1. Computing the recurrence with a local variable, as shown in the code in Figure\nobreakspace  {}\ref  {fig:prefixsum_optimized}, is able to reduce the latency in the recurrence and achieve a loop II of 1.\relax }}{147}{figure.caption.79}}
\newlabel{fig:architecture_prefixsum}{{8.4}{147}{Part a) displays an architecture corresponding to the code in Figure~\ref {fig:prefixsumSW}. The dependence on the \lstinline {out[]} array can prevent achieving a loop II of 1. Computing the recurrence with a local variable, as shown in the code in Figure~\ref {fig:prefixsum_optimized}, is able to reduce the latency in the recurrence and achieve a loop II of 1.\relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces  An example of a histogram. \relax }}{148}{figure.caption.80}}
\newlabel{fig:histogram_introd}{{8.5}{148}{An example of a histogram. \relax }{figure.caption.80}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/histogramSW.cpp}{148}{lstlisting.8.-39}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces  Original code for calculating the histogram. The \lstinline {for} loop iterates across the input array and increments the corresponding element of the \lstinline {hist} array. \relax }}{148}{figure.caption.81}}
\newlabel{fig:histogramSW}{{8.6}{148}{Original code for calculating the histogram. The \lstinline {for} loop iterates across the input array and increments the corresponding element of the \lstinline {hist} array. \relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Histogram}{148}{section.8.2}}
\newlabel{sec:histogram}{{8.2}{148}{Histogram}{section.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces  An architecture resulting from the code in Figure \ref  {fig:histogramSW}. The \lstinline {val} data from the \lstinline {in} array is used to index into the \lstinline {hist} array. This data is incremented and stored back into the same location.\relax }}{149}{figure.caption.82}}
\newlabel{fig:architecture_histogram}{{8.7}{149}{An architecture resulting from the code in Figure \ref {fig:histogramSW}. The \lstinline {val} data from the \lstinline {in} array is used to index into the \lstinline {hist} array. This data is incremented and stored back into the same location.\relax }{figure.caption.82}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Histogram Optimization and False Dependencies}{149}{section.8.3}}
\@writefile{lol}{\contentsline {lstlisting}{examples/histogram\textunderscore dependence.cpp}{150}{lstlisting.8.-40}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces  An alternative function for computing a histogram. By restricting the inputs and indicating this restriction to Vivado\textsuperscript  {\textregistered } HLS\xspace  via the \lstinline |dependence| directive, II=1 can be achieved without significantly altering the code. \relax }}{150}{figure.caption.83}}
\newlabel{fig:histogram_dependence}{{8.8}{150}{An alternative function for computing a histogram. By restricting the inputs and indicating this restriction to \VHLS via the \lstinline |dependence| directive, II=1 can be achieved without significantly altering the code. \relax }{figure.caption.83}{}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{150}}
\@gls@reference{main}{ffg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{150}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{150}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{150}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{150}}
\citation{winterstein13dynamic,liu17elasticflow,dai17dynamic}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces  An architecture resulting from the code in Figure \ref  {fig:histogramSW} when the \lstinline |hist| array is completely partitioned.\relax }}{151}{figure.caption.84}}
\newlabel{fig:histogram_partitioned}{{8.9}{151}{An architecture resulting from the code in Figure \ref {fig:histogramSW} when the \lstinline |hist| array is completely partitioned.\relax }{figure.caption.84}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/histogram\textunderscore opt1.cpp}{152}{lstlisting.8.-41}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.10}{\ignorespaces  Removing the read after write dependency from the \lstinline {for} loop. This requires an \lstinline {if/else} structure that may seem like it is adding unnecessary complexity to the design. However, it allows for more effective pipelining despite the fact that the datapath is more complicated. \relax }}{152}{figure.caption.85}}
\newlabel{fig:histogramOpt1}{{8.10}{152}{Removing the read after write dependency from the \lstinline {for} loop. This requires an \lstinline {if/else} structure that may seem like it is adding unnecessary complexity to the design. However, it allows for more effective pipelining despite the fact that the datapath is more complicated. \relax }{figure.caption.85}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Increasing Histogram Performance}{152}{section.8.4}}
\citation{dean08mapreduce}
\@writefile{lof}{\contentsline {figure}{\numberline {8.11}{\ignorespaces  A depiction of the datapath corresponding to the code in Figure \ref  {fig:histogramOpt1}. There are two separate portions corresponding to the \lstinline {if} and \lstinline {else} clauses. The figure shows the important portions of the computation, and leaves out some minor details. \relax }}{153}{figure.caption.86}}
\newlabel{fig:architecture_histogram_restructured}{{8.11}{153}{A depiction of the datapath corresponding to the code in Figure \ref {fig:histogramOpt1}. There are two separate portions corresponding to the \lstinline {if} and \lstinline {else} clauses. The figure shows the important portions of the computation, and leaves out some minor details. \relax }{figure.caption.86}{}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{152}}
\@gls@reference{main}{arraypartitioning}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{152}}
\@gls@reference{acronym}{pe}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{153}}
\@gls@reference{main}{peg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{153}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.12}{\ignorespaces The histogram computation implemented using a map-reduce pattern. The processing element (PE) in Part a) is the same architecture as shown in Figure \ref  {fig:architecture_histogram_restructured}. The \lstinline |in| array is partitioned and each partition is processed by a separate \gls {pe}. The merge block combines the individual histograms to create the final histogram. \relax }}{154}{figure.caption.87}}
\@gls@reference{acronym}{pe}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{153}}
\newlabel{fig:architecture_histogram_parallel}{{8.12}{154}{The histogram computation implemented using a map-reduce pattern. The processing element (PE) in Part a) is the same architecture as shown in Figure \ref {fig:architecture_histogram_restructured}. The \lstinline |in| array is partitioned and each partition is processed by a separate \gls {pe}. The merge block combines the individual histograms to create the final histogram. \relax }{figure.caption.87}{}}
\@gls@reference{acronym}{pe}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{154}}
\@gls@reference{acronym}{pe}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{154}}
\@gls@reference{main}{taskpipelining}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{154}}
\@writefile{lol}{\contentsline {lstlisting}{examples/histogram\textunderscore parallel.cpp}{155}{lstlisting.8.-42}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces  Another implementation of histogram that uses task level parallelism and pipelining. The histogram operation is split into two sub tasks, which are executed in the two \lstinline {histogram_map} functions. These results are combined in the final histogram result using the \lstinline {histogram_reduce} function. The \lstinline {histogram} function is the top level function that connects these three functions together. \relax }}{155}{figure.caption.88}}
\newlabel{fig:histogram_parallel}{{8.13}{155}{Another implementation of histogram that uses task level parallelism and pipelining. The histogram operation is split into two sub tasks, which are executed in the two \lstinline {histogram_map} functions. These results are combined in the final histogram result using the \lstinline {histogram_reduce} function. The \lstinline {histogram} function is the top level function that connects these three functions together. \relax }{figure.caption.88}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Conclusion}{156}{section.8.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Video Systems}{157}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:video}{{9}{157}{Video Systems}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Background}{157}{section.9.1}}
\newlabel{chapVideo}{{9.1}{157}{Background}{section.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Scanline processing order for video frames.\relax }}{157}{figure.caption.89}}
\newlabel{fig:scanlineOrder}{{9.1}{157}{Scanline processing order for video frames.\relax }{figure.caption.89}{}}
\citation{bayer76}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Representing Video Pixels}{158}{subsection.9.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Digital Video Formats}{158}{subsection.9.1.2}}
\newlabel{sec:video:formats}{{9.1.2}{158}{Digital Video Formats}{subsection.9.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Typical synchronization signals in a 1080P60 high definition video signal.\relax }}{159}{figure.caption.90}}
\newlabel{fig:video_syncs}{{9.2}{159}{Typical synchronization signals in a 1080P60 high definition video signal.\relax }{figure.caption.90}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/video\textunderscore simple.c}{160}{lstlisting.9.-43}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Code implementing a simple video filter.\relax }}{160}{figure.caption.91}}
\newlabel{fig:videoSimple}{{9.3}{160}{Code implementing a simple video filter.\relax }{figure.caption.91}{}}
\citation{ARMAXI4}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces Integration of a video design with BRAM interfaces.\relax }}{161}{figure.caption.92}}
\newlabel{fig:video:BRAM_interface}{{9.4}{161}{Integration of a video design with BRAM interfaces.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.3}Video Processing System Architectures}{161}{subsection.9.1.3}}
\newlabel{sec:video:architectures}{{9.1.3}{161}{Video Processing System Architectures}{subsection.9.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces Integration of a video design with external memory interfaces.\relax }}{162}{figure.caption.93}}
\newlabel{fig:video:DDR_interface}{{9.5}{162}{Integration of a video design with external memory interfaces.\relax }{figure.caption.93}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces Integration of a video design with external memory interfaces through a DMA component.\relax }}{163}{figure.caption.94}}
\newlabel{fig:video:DDR_DMA_interface}{{9.6}{163}{Integration of a video design with external memory interfaces through a DMA component.\relax }{figure.caption.94}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Coding styles for modelling streaming interfaces in HLS.\relax }}{163}{figure.caption.95}}
\newlabel{fig:video:stream_interfaces}{{9.7}{163}{Coding styles for modelling streaming interfaces in HLS.\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Integration of a video design with streaming interfaces.\relax }}{164}{figure.caption.96}}
\newlabel{fig:video:streaming_interface}{{9.8}{164}{Integration of a video design with streaming interfaces.\relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Implementation}{164}{section.9.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Line Buffers and Frame Buffers}{164}{subsection.9.2.1}}
\newlabel{sec:video:buffering}{{9.2.1}{164}{Line Buffers and Frame Buffers}{subsection.9.2.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/video\textunderscore 2dfilter.c}{165}{lstlisting.9.-50}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Code implementing a 2D filter without an explicit line buffer.\relax }}{165}{figure.caption.97}}
\newlabel{fig:video:2Dfilter}{{9.9}{165}{Code implementing a 2D filter without an explicit line buffer.\relax }{figure.caption.97}{}}
\citation{bayliss12sdram}
\citation{hegarty2016rigel}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{164}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{164}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{164}}
\@gls@reference{main}{ffg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{164}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Causal Filters}{166}{subsection.9.2.2}}
\@writefile{lol}{\contentsline {lstlisting}{examples/video\textunderscore 2dfilter\textunderscore linebuffer.c}{167}{lstlisting.9.-51}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Code implementing a 2D filter with an explicit line buffer.\relax }}{167}{figure.caption.98}}
\newlabel{fig:video:2Dfilter_linebuffer}{{9.10}{167}{Code implementing a 2D filter with an explicit line buffer.\relax }{figure.caption.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces  Memories implemented by the code in Figure \ref  {fig:video:2Dfilter_linebuffer}. These memories store a portion of the input image shown in the diagram on the right at the end of a particular iteration of the loop. The pixels outlined in black are stored in the line buffer and the pixels outlined in red are stored in the window buffer.\relax }}{168}{figure.caption.99}}
\newlabel{fig:video:video_buffers}{{9.11}{168}{Memories implemented by the code in Figure \ref {fig:video:2Dfilter_linebuffer}. These memories store a portion of the input image shown in the diagram on the right at the end of a particular iteration of the loop. The pixels outlined in black are stored in the line buffer and the pixels outlined in red are stored in the window buffer.\relax }{figure.caption.99}{}}
\newlabel{fig:dft-visualization}{{9.11}{168}{Memories implemented by the code in Figure \ref {fig:video:2Dfilter_linebuffer}. These memories store a portion of the input image shown in the diagram on the right at the end of a particular iteration of the loop. The pixels outlined in black are stored in the line buffer and the pixels outlined in red are stored in the window buffer.\relax }{figure.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.3}Boundary Conditions}{168}{subsection.9.2.3}}
\@writefile{lol}{\contentsline {lstlisting}{examples/video\textunderscore 2dfilter\textunderscore linebuffer\textunderscore extended.c}{169}{lstlisting.9.-52}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.12}{\ignorespaces Code implementing a 2D filter with an explicit line buffer. The iteration space is extended by 1 to allow the filter to be implemented without a spatial shift.\relax }}{169}{figure.caption.100}}
\newlabel{fig:video:2Dfilter_linebuffer_extended}{{9.12}{169}{Code implementing a 2D filter with an explicit line buffer. The iteration space is extended by 1 to allow the filter to be implemented without a spatial shift.\relax }{figure.caption.100}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.13}{\ignorespaces Results of different filter implementations. The reference output in image b is produced by the code in Figure \ref  {fig:video:2Dfilter}. The shifted output in image c is produced by the code in Figure \ref  {fig:video:2Dfilter_linebuffer}. The output in image d is produced by the code in Figure \ref  {fig:video:2Dfilter_linebuffer_extended} and is identical to image b.\relax }}{170}{figure.caption.101}}
\newlabel{fig:video:filter2D_results_withshifting}{{9.13}{170}{Results of different filter implementations. The reference output in image b is produced by the code in Figure \ref {fig:video:2Dfilter}. The shifted output in image c is produced by the code in Figure \ref {fig:video:2Dfilter_linebuffer}. The output in image d is produced by the code in Figure \ref {fig:video:2Dfilter_linebuffer_extended} and is identical to image b.\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.14}{\ignorespaces Timeline of execution of code implemented with line buffers. The top timeline shows the behavior of the code in Figure \ref  {fig:video:2Dfilter_linebuffer}. The bottom timeline shows the behavior of the code in Figure \ref  {fig:video:2Dfilter_linebuffer_extended}. The pixel marked in red is output on the same cycle in both implementations. In the first case it is interpreted to be the second pixel of the second line and in the second case, it is interpreted as the first pixel of the first line.\relax }}{170}{figure.caption.102}}
\newlabel{fig:video:timelines}{{9.14}{170}{Timeline of execution of code implemented with line buffers. The top timeline shows the behavior of the code in Figure \ref {fig:video:2Dfilter_linebuffer}. The bottom timeline shows the behavior of the code in Figure \ref {fig:video:2Dfilter_linebuffer_extended}. The pixel marked in red is output on the same cycle in both implementations. In the first case it is interpreted to be the second pixel of the second line and in the second case, it is interpreted as the first pixel of the first line.\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.15}{\ignorespaces Examples of the effect of different kinds of boundary conditions.\relax }}{171}{figure.caption.103}}
\newlabel{fig:video:boundary_conditions}{{9.15}{171}{Examples of the effect of different kinds of boundary conditions.\relax }{figure.caption.103}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Conclusion}{171}{section.9.3}}
\@writefile{lol}{\contentsline {lstlisting}{examples/video\textunderscore 2dfilter\textunderscore linebuffer\textunderscore extended\textunderscore constant.c}{172}{lstlisting.9.-53}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.16}{\ignorespaces Code implementing a 2D filter with an explicit line buffer and constant extension to handle the boundary condition. Although correct, this code is relatively expensive to implement.\relax }}{172}{figure.caption.104}}
\newlabel{fig:video:boundaryConditionExtendBad}{{9.16}{172}{Code implementing a 2D filter with an explicit line buffer and constant extension to handle the boundary condition. Although correct, this code is relatively expensive to implement.\relax }{figure.caption.104}{}}
\citation{knuth1998art}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Sorting Algorithms}{173}{chapter.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:sorting}{{10}{173}{Sorting Algorithms}{chapter.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Introduction}{173}{section.10.1}}
\newlabel{sec:sorting_introduction}{{10.1}{173}{Introduction}{section.10.1}{}}
\citation{marcelino2008sorting,mueller2012sorting,matai2016sorting}
\@gls@reference{main}{stable_sort}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{174}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Insertion Sort}{174}{section.10.2}}
\newlabel{sec:insertion_sort}{{10.2}{174}{Insertion Sort}{section.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces The Insertion Sort algorithm operating on an array. The initial array is shown at the top. In each step of the algorithm, the underlined algorithm is considered and placed into sorted order of the elements to it's left. At each stage, the shaded elements are in sorted order. \relax }}{175}{figure.caption.105}}
\newlabel{eq:insertion_sort}{{10.1}{175}{The Insertion Sort algorithm operating on an array. The initial array is shown at the top. In each step of the algorithm, the underlined algorithm is considered and placed into sorted order of the elements to it's left. At each stage, the shaded elements are in sorted order. \relax }{figure.caption.105}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/insertion\textunderscore sort.cpp}{175}{lstlisting.10.-54}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces  The complete code for insertion sort. The outer \lstinline {for} loop iterates across the elements one at a time. The inner \lstinline {while} loop moves the current element into sorted place. \relax }}{175}{figure.caption.106}}
\newlabel{fig:insertion_sort.cpp}{{10.2}{175}{The complete code for insertion sort. The outer \lstinline {for} loop iterates across the elements one at a time. The inner \lstinline {while} loop moves the current element into sorted place. \relax }{figure.caption.106}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Basic Insertion Sort Implementation}{175}{subsection.10.2.1}}
\newlabel{sec:basic_insertion_sort}{{10.2.1}{175}{Basic Insertion Sort Implementation}{subsection.10.2.1}{}}
\citation{sedgewickalgorithmsinC}
\@writefile{lot}{\contentsline {table}{\numberline {10.1}{\ignorespaces Possible options to optimize the basic \lstinline {insertion_sort} function in Figure \ref  {fig:insertion_sort.cpp} through directives.\relax }}{176}{table.caption.107}}
\newlabel{tbl:sw_insertionsort_vs_hardwareA}{{10.1}{176}{Possible options to optimize the basic \lstinline {insertion_sort} function in Figure \ref {fig:insertion_sort.cpp} through directives.\relax }{table.caption.107}{}}
\newlabel{table:case-studies}{{10.1}{176}{Possible options to optimize the basic \lstinline {insertion_sort} function in Figure \ref {fig:insertion_sort.cpp} through directives.\relax }{table.caption.107}{}}
\citation{ug574,Abdelhadi2014multiport,Laforest2014multiport}
\@writefile{lol}{\contentsline {lstlisting}{examples/insertion\textunderscore sort\textunderscore relaxed.cpp}{177}{lstlisting.10.-55}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Refactored insertion sort for Option 1 in Table \ref  {table:case-studies}.\relax }}{177}{figure.caption.108}}
\newlabel{fig:insertion_sort_relaxed.cpp}{{10.3}{177}{Refactored insertion sort for Option 1 in Table \ref {table:case-studies}.\relax }{figure.caption.108}{}}
\@gls@reference{main}{arraypartitioning}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{177}}
\citation{george2014hardware,matai2014enabling}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Parallelising Insertion Sort}{178}{subsection.10.2.2}}
\@writefile{lol}{\contentsline {lstlisting}{examples/insertion\textunderscore sort\textunderscore parallel.cpp}{179}{lstlisting.10.-56}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Refactored insertion sort for Option 3 in Table \ref  {table:case-studies}.\relax }}{179}{figure.caption.109}}
\newlabel{fig:insertion_sort_parallel.cpp}{{10.4}{179}{Refactored insertion sort for Option 3 in Table \ref {table:case-studies}.\relax }{figure.caption.109}{}}
\citation{ortiz2011streaming,bednara2000tradeoff,marcelino2008sorting,arcas2014empirical}
\@gls@reference{acronym}{ssa}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@gls@reference{main}{ssag}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@gls@reference{acronym}{ssa}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@gls@reference{main}{sorting_cell}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@gls@reference{main}{systolic_array}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.3}Explicit Systolic Array For Insertion Sort}{180}{subsection.10.2.3}}
\newlabel{sec:insertion_cells}{{10.2.3}{180}{Explicit Systolic Array For Insertion Sort}{subsection.10.2.3}{}}
\@gls@reference{main}{systolic_array}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{180}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces  The architecture of one insertion cell. Each cell holds exactly one value in the register \lstinline {local}. On each execution it receives an input value \lstinline {in}, compares that to its \lstinline {local} value, and writes the smaller of the two to \lstinline {output}. Sorting \lstinline {N} values requires \lstinline {N} cells. \relax }}{181}{figure.caption.110}}
\newlabel{fig:insertion_cell}{{10.5}{181}{The architecture of one insertion cell. Each cell holds exactly one value in the register \lstinline {local}. On each execution it receives an input value \lstinline {in}, compares that to its \lstinline {local} value, and writes the smaller of the two to \lstinline {output}. Sorting \lstinline {N} values requires \lstinline {N} cells. \relax }{figure.caption.110}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/insertion\textunderscore cell\textunderscore sort.cpp}{181}{lstlisting.10.-57}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces  The Vivado\textsuperscript  {\textregistered } HLS\xspace  C code corresponding to one insertion cell \lstinline {cell0}. The other cells have the exact same code except with a different function name (\lstinline {cell1}, \lstinline {cell2}, etc.). The code performs the same functionality as shown in the architectural diagram in Figure \ref  {fig:insertion_cell}. It uses the \lstinline {hls:stream} interface for the input and output variables. \lstinline {hls::stream} provides a convenient method to create FIFOs that work both for synthesis and simulation. \relax }}{181}{figure.caption.111}}
\newlabel{fig:insertion_cell_sort.cpp}{{10.6}{181}{The \VHLS C code corresponding to one insertion cell \lstinline {cell0}. The other cells have the exact same code except with a different function name (\lstinline {cell1}, \lstinline {cell2}, etc.). The code performs the same functionality as shown in the architectural diagram in Figure \ref {fig:insertion_cell}. It uses the \lstinline {hls:stream} interface for the input and output variables. \lstinline {hls::stream} provides a convenient method to create FIFOs that work both for synthesis and simulation. \relax }{figure.caption.111}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/partial\textunderscore insertion\textunderscore cell\textunderscore sort.cpp}{182}{lstlisting.10.-58}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces  Insertion cell sorting for eight elements. The function takes an input \lstinline {hls::stream} and outputs the elements in sorted order one at a time through the variable \lstinline {out}. The order starts with the smallest element first, and then continues on to increasingly larger elements. \relax }}{182}{figure.caption.112}}
\newlabel{fig:partial_insertion_cell_sort.cpp}{{10.7}{182}{Insertion cell sorting for eight elements. The function takes an input \lstinline {hls::stream} and outputs the elements in sorted order one at a time through the variable \lstinline {out}. The order starts with the smallest element first, and then continues on to increasingly larger elements. \relax }{figure.caption.112}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/insertion\textunderscore cell\textunderscore sort\textendash top.cpp}{184}{lstlisting.10.-59}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces  The testbench for the \lstinline {insertion_cell_sort} function. \relax }}{184}{figure.caption.113}}
\newlabel{fig:insertion_cell_sort_test.cpp}{{10.8}{184}{The testbench for the \lstinline {insertion_cell_sort} function. \relax }{figure.caption.113}{}}
\citation{knuth1998art}
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces The Merge Sort algorithm operating on an array. The initial state where each element is considered to be a sorted subarray of length one is shown at the top. At each step of the algorithm, subarrays are merged placing the shaded elements are in sorted order.\relax }}{185}{figure.caption.114}}
\newlabel{fig:merge_sort_behavior}{{10.9}{185}{The Merge Sort algorithm operating on an array. The initial state where each element is considered to be a sorted subarray of length one is shown at the top. At each step of the algorithm, subarrays are merged placing the shaded elements are in sorted order.\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces The process of merging two sorted arrays. The initial state is shown at the top. In each step of the algorithm, the underlined elements are considered and one is placed into sorted order in the output array.\relax }}{185}{figure.caption.115}}
\newlabel{fig:merge_behavior}{{10.10}{185}{The process of merging two sorted arrays. The initial state is shown at the top. In each step of the algorithm, the underlined elements are considered and one is placed into sorted order in the output array.\relax }{figure.caption.115}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Merge Sort}{185}{section.10.3}}
\newlabel{sec:sort:merge}{{10.3}{185}{Merge Sort}{section.10.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.1}Basic Merge Sort}{186}{subsection.10.3.1}}
\newlabel{fig:merge_sort.cpp}{{10.3.1}{186}{Basic Merge Sort}{figure.caption.116}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/merge\textunderscore sort.cpp}{187}{lstlisting.10.-60}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.11}{\ignorespaces  A non-recursive implementation of merge sort. The \lstinline {merge_sort()} function iteratively merges subarrays until the entire array has been sorted. \relax }}{187}{figure.caption.116}}
\newlabel{fig:merge_sort.cpp}{{10.11}{187}{A non-recursive implementation of merge sort. The \lstinline {merge_sort()} function iteratively merges subarrays until the entire array has been sorted. \relax }{figure.caption.116}{}}
\@gls@reference{acronym}{hls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{188}}
\@gls@reference{main}{hlsg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{188}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.2}Restructured Merge Sort}{189}{subsection.10.3.2}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{189}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{189}}
\@writefile{lol}{\contentsline {lstlisting}{examples/merge\textunderscore sort\textunderscore restructured.cpp}{190}{lstlisting.10.-61}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.12}{\ignorespaces Restructured code for the \lstinline {merge()} function, which can achieve a loop II of 1 in Vivado\textsuperscript  {\textregistered } HLS\xspace  .\relax }}{190}{figure.caption.117}}
\newlabel{fig:merge_sort_restructured.cpp}{{10.12}{190}{Restructured code for the \lstinline {merge()} function, which can achieve a loop II of 1 in \VHLS .\relax }{figure.caption.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.13}{\ignorespaces Behavior of the restructured code in Figure \ref  {fig:merge_sort_restructured.cpp}.\relax }}{190}{figure.caption.118}}
\newlabel{fig:merge_sort_restructured_behavior}{{10.13}{190}{Behavior of the restructured code in Figure \ref {fig:merge_sort_restructured.cpp}.\relax }{figure.caption.118}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/merge\textunderscore sort\textunderscore loop\textunderscore merged.cpp}{191}{lstlisting.10.-62}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.14}{\ignorespaces Restructured code for Merge Sort which can achieve a loop II of 1 with fewer pipeline bubbles in Vivado\textsuperscript  {\textregistered } HLS\xspace  .\relax }}{191}{figure.caption.119}}
\newlabel{fig:merge_sort_loop_merged.cpp}{{10.14}{191}{Restructured code for Merge Sort which can achieve a loop II of 1 with fewer pipeline bubbles in \VHLS .\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.15}{\ignorespaces Dataflow pipelined architecture for implementing 4 stages of Merge Sort. This architecture can sort up to 16 elements.\relax }}{192}{figure.caption.120}}
\newlabel{fig:restructured_mergesort_dataflow}{{10.15}{192}{Dataflow pipelined architecture for implementing 4 stages of Merge Sort. This architecture can sort up to 16 elements.\relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Conclusion}{192}{section.10.4}}
\@writefile{lol}{\contentsline {lstlisting}{examples/merge\textunderscore sort\textunderscore parallel.cpp}{193}{lstlisting.10.-63}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.16}{\ignorespaces Restructured code for Merge Sort which can be implemented as a dataflow pipeline by Vivado\textsuperscript  {\textregistered } HLS\xspace  .\relax }}{193}{figure.caption.121}}
\newlabel{fig:merge_sort_parallel.cpp}{{10.16}{193}{Restructured code for Merge Sort which can be implemented as a dataflow pipeline by \VHLS .\relax }{figure.caption.121}{}}
\@gls@reference{main}{systolic_array}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{194}}
\citation{huffman1952method}
\citation{flannery1992numerical}
\citation{deutsch1996deflate}
\citation{pennebaker1992jpeg}
\citation{sherigar2004huffman}
\citation{witten1987arithmetic}
\citation{langdon1990arithmetic}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Huffman Encoding}{195}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:huffman}{{11}{195}{Huffman Encoding}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Background}{195}{section.11.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces  The Canonical Huffman Encoding process. The symbols are filtered and sorted, and used to build a Huffman tree. Instead of passing the entire tree to the decoder (as is done in ``basic'' Huffman coding), the encoding is done such that only the length of the symbols in the tree is required by the decoder. Note that the final canonical tree is different from the initial tree created near the beginning of the process.\relax }}{196}{figure.caption.122}}
\newlabel{fig:canonical_huffman_flow}{{11.1}{196}{The Canonical Huffman Encoding process. The symbols are filtered and sorted, and used to build a Huffman tree. Instead of passing the entire tree to the decoder (as is done in ``basic'' Huffman coding), the encoding is done such that only the length of the symbols in the tree is required by the decoder. Note that the final canonical tree is different from the initial tree created near the beginning of the process.\relax }{figure.caption.122}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore encoding.cpp}{198}{lstlisting.11.-64}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore encoding.cpp}{199}{lstlisting.11.-65}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces  The ``top'' \lstinline {huffman_encoding} function. It defines the arrays and variables between the various subfunctions. These are described graphically in Figures \ref  {fig:canonical_huffman_flow} and \ref  {fig:che_dataflow}. \relax }}{199}{figure.caption.124}}
\newlabel{fig:huffman_encoding.cpp}{{11.2}{199}{The ``top'' \lstinline {huffman_encoding} function. It defines the arrays and variables between the various subfunctions. These are described graphically in Figures \ref {fig:canonical_huffman_flow} and \ref {fig:che_dataflow}. \relax }{figure.caption.124}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Implementation}{199}{section.11.2}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman.h}{200}{lstlisting.11.-66}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces  The parameters, custom data type, and function interface for the top level function \lstinline {huffman_encoding}. \relax }}{200}{figure.caption.125}}
\newlabel{fig:huffman_h}{{11.3}{200}{The parameters, custom data type, and function interface for the top level function \lstinline {huffman_encoding}. \relax }{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces  The block diagram for our hardware implementation of canonical Huffman encoding. The gray blocks represent the significant input and output data that is generated and consumed by the different subfunctions. The white blocks correspond to the functions (computational cores). Note that the array initial bit length appears twice to allow the figure to be more clear.\relax }}{201}{figure.caption.126}}
\newlabel{fig:che_dataflow}{{11.4}{201}{The block diagram for our hardware implementation of canonical Huffman encoding. The gray blocks represent the significant input and output data that is generated and consumed by the different subfunctions. The white blocks correspond to the functions (computational cores). Note that the array initial bit length appears twice to allow the figure to be more clear.\relax }{figure.caption.126}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore filter.cpp}{202}{lstlisting.11.-67}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces  The \lstinline {filter} function iterates across the input array \lstinline {in} and add any \lstinline {Symbol} entry with a non-zero \lstinline {frequency} field to the output array \lstinline {out}. Additionally, it records the number of non-zero frequency elements and passes that in the output argument \lstinline {n}. \relax }}{202}{figure.caption.127}}
\newlabel{fig:huffman_filter.cpp}{{11.5}{202}{The \lstinline {filter} function iterates across the input array \lstinline {in} and add any \lstinline {Symbol} entry with a non-zero \lstinline {frequency} field to the output array \lstinline {out}. Additionally, it records the number of non-zero frequency elements and passes that in the output argument \lstinline {n}. \relax }{figure.caption.127}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Filter}{202}{subsection.11.2.1}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{202}}
\@gls@reference{main}{rtlg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{202}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.2}Sort}{203}{subsection.11.2.2}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore sort.cpp}{204}{lstlisting.11.-68}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore sort.cpp}{205}{lstlisting.11.-69}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces  The \lstinline {sort} function employs a radix sort on the input symbols based upon their frequency values. \relax }}{205}{figure.caption.129}}
\newlabel{fig:huffman_sort.cpp}{{11.6}{205}{The \lstinline {sort} function employs a radix sort on the input symbols based upon their frequency values. \relax }{figure.caption.129}{}}
\@gls@reference{main}{stable_sort}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{205}}
\citation{misra2012}
\citation{sedgewickalgorithmsinC}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.3}Create Tree}{207}{subsection.11.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces  The \lstinline {Symbol} array \lstinline {in} is used to create the Huffman tree. The tree is shown graphically along with the corresponding values for the four arrays used to represent the tree (\lstinline {intermediate}, \lstinline {left}, \lstinline {right}, and \lstinline {parent}). \relax }}{208}{figure.caption.130}}
\newlabel{fig:huffman_create_tree}{{11.7}{208}{The \lstinline {Symbol} array \lstinline {in} is used to create the Huffman tree. The tree is shown graphically along with the corresponding values for the four arrays used to represent the tree (\lstinline {intermediate}, \lstinline {left}, \lstinline {right}, and \lstinline {parent}). \relax }{figure.caption.130}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore create\textunderscore tree.cpp}{209}{lstlisting.11.-70}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore create\textunderscore tree.cpp}{210}{lstlisting.11.-71}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore create\textunderscore tree.cpp}{210}{lstlisting.11.-72}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.8}{\ignorespaces  The complete code for Huffman tree creation. The code takes as input the sorted \lstinline {Symbol} array \lstinline {in}, the number of elements in that array \lstinline {n}, and outputs the Huffman tree in the three arrays \lstinline {left}, \lstinline {right}, and \lstinline {parent}. \relax }}{210}{figure.caption.133}}
\newlabel{fig:huffman_create_tree.cpp}{{11.8}{210}{The complete code for Huffman tree creation. The code takes as input the sorted \lstinline {Symbol} array \lstinline {in}, the number of elements in that array \lstinline {n}, and outputs the Huffman tree in the three arrays \lstinline {left}, \lstinline {right}, and \lstinline {parent}. \relax }{figure.caption.133}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.4}Compute Bit Length}{211}{subsection.11.2.4}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore compute\textunderscore bit\textunderscore length.cpp}{212}{lstlisting.11.-73}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.9}{\ignorespaces The complete code for determining the number of symbols at each bit length.\relax }}{212}{figure.caption.134}}
\newlabel{fig:huffman_compute_bit_length.cpp}{{11.9}{212}{The complete code for determining the number of symbols at each bit length.\relax }{figure.caption.134}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.5}Truncate Tree}{213}{subsection.11.2.5}}
\newlabel{sec:huffman_truncate_tree}{{11.2.5}{213}{Truncate Tree}{subsection.11.2.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore truncate\textunderscore tree.cpp}{214}{lstlisting.11.-74}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore truncate\textunderscore tree.cpp}{215}{lstlisting.11.-75}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.10}{\ignorespaces The complete code for rearranging the Huffman tree such that the depth of any node is under the target specified by the parameter \lstinline {MAX_CODEWORD_LENGTH}. \relax }}{215}{figure.caption.136}}
\newlabel{fig:huffman_truncate_tree.cpp}{{11.10}{215}{The complete code for rearranging the Huffman tree such that the depth of any node is under the target specified by the parameter \lstinline {MAX_CODEWORD_LENGTH}. \relax }{figure.caption.136}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.6}Canonize Tree}{215}{subsection.11.2.6}}
\newlabel{sec:huffman_canonize_tree}{{11.2.6}{215}{Canonize Tree}{subsection.11.2.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore canonize\textunderscore tree.cpp}{216}{lstlisting.11.-76}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.11}{\ignorespaces  The complete code for canonizing the Huffman tree, which determins the number of bits for each symbol. \relax }}{216}{figure.caption.137}}
\newlabel{fig:huffman_canonize_tree.cpp}{{11.11}{216}{The complete code for canonizing the Huffman tree, which determins the number of bits for each symbol. \relax }{figure.caption.137}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore canonize\textunderscore tree\textunderscore alternate.cpp}{217}{lstlisting.11.-77}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.12}{\ignorespaces  Alternate loop structure for the \lstinline {process_symbols} loop in Figure \ref  {fig:huffman_canonize_tree.cpp}. \relax }}{217}{figure.caption.138}}
\newlabel{fig:huffman_canonize_alternate}{{11.12}{217}{Alternate loop structure for the \lstinline {process_symbols} loop in Figure \ref {fig:huffman_canonize_tree.cpp}. \relax }{figure.caption.138}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.7}Create Codeword}{217}{subsection.11.2.7}}
\newlabel{sec:create_codewords}{{11.2.7}{217}{Create Codeword}{subsection.11.2.7}{}}
\newlabel{eq:first_codeword_recurrence}{{11.3}{217}{Create Codeword}{equation.11.2.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore create\textunderscore codeword.cpp}{219}{lstlisting.11.-78}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.13}{\ignorespaces  The complete code for generating the canonical Huffman codewords for each of the symbols. The codewords can be computed with knowledge of number of bits that each symbol uses (stored in the input array \lstinline {symbol_bits[]}). Additionally, we have another input array \lstinline {codeword_length_histogram[]} which stores at each entry the number of symbols with codewords at that bit length. The output is the code word for each symbol stored in the \lstinline {encoding[]} array. \relax }}{219}{figure.caption.139}}
\newlabel{fig:huffman_create_codeword.cpp}{{11.13}{219}{The complete code for generating the canonical Huffman codewords for each of the symbols. The codewords can be computed with knowledge of number of bits that each symbol uses (stored in the input array \lstinline {symbol_bits[]}). Additionally, we have another input array \lstinline {codeword_length_histogram[]} which stores at each entry the number of symbols with codewords at that bit length. The output is the code word for each symbol stored in the \lstinline {encoding[]} array. \relax }{figure.caption.139}{}}
\newlabel{eq:bit_lengths}{{11.4}{220}{Create Codeword}{equation.11.2.4}{}}
\newlabel{eq:symbols}{{11.5}{220}{Create Codeword}{equation.11.2.5}{}}
\newlabel{eq:codewords}{{11.6}{220}{Create Codeword}{equation.11.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.8}Testbench}{220}{subsection.11.2.8}}
\newlabel{sec:huffman_testbench}{{11.2.8}{220}{Testbench}{subsection.11.2.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore encoding\textunderscore test.cpp}{221}{lstlisting.11.-79}}
\@writefile{lol}{\contentsline {lstlisting}{examples/huffman\textunderscore encoding\textunderscore test.cpp}{222}{lstlisting.11.-80}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.14}{\ignorespaces  The complete code for the canonical Huffman encoding testbench. The code initializes the \lstinline {in} array with data from an input file. It passes that into the top \lstinline {huffman_encoding} function. Then it stores the resulting codewords into a file, and compares that with another golden reference file. It prints out the results of the comparison, and returns the appropriate value.\relax }}{222}{figure.caption.141}}
\newlabel{fig:huffman_encoding_test.cpp}{{11.14}{222}{The complete code for the canonical Huffman encoding testbench. The code initializes the \lstinline {in} array with data from an input file. It passes that into the top \lstinline {huffman_encoding} function. Then it stores the resulting codewords into a file, and compares that with another golden reference file. It prints out the results of the comparison, and returns the appropriate value.\relax }{figure.caption.141}{}}
\bibstyle{plainnat}
\bibdata{all}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Conclusion}{223}{section.11.3}}
\bibcite{Abdelhadi2014multiport}{{1}{2014}{{Abdelhadi and Lemieux}}{{}}}
\bibcite{systemc}{{2}{2017}{{Acc}}{{}}}
\bibcite{ahmed1982highly}{{3}{1982}{{Ahmed et~al.}}{{Ahmed, Delosme, and Morf}}}
\bibcite{andraka1996building}{{4}{1996}{{Andraka}}{{}}}
\bibcite{arcas2014empirical}{{5}{2014}{{Arcas-Abella et~al.}}{{}}}
\bibcite{ARMAXI4}{{6}{2013}{{ARM}}{{}}}
\bibcite{bayer76}{{7}{1976}{{Bayer}}{{}}}
\bibcite{bayliss12sdram}{{8}{2012}{{Bayliss and Constantinides}}{{}}}
\bibcite{bednara2000tradeoff}{{9}{2000}{{Bednara et~al.}}{{}}}
\bibcite{betz1997vpr}{{10}{1997}{{Betz and Rose}}{{}}}
\bibcite{blelloch1990prefix}{{11}{1990}{{Blelloch}}{{}}}
\bibcite{brown1996fpga}{{12}{1996}{{Brown and Rose}}{{}}}
\bibcite{canis2011legup}{{13}{2011}{{Canis et~al.}}{{Canis, Choi, Aldham, Zhang, Kammoona, Anderson, Brown, and Czajkowski}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{225}{chapter*.142}}
\bibcite{chen2012fpga}{{14}{2012}{{Chen et~al.}}{{Chen, Cong, Yan, and Zou}}}
\bibcite{cong2011high}{{15}{2011}{{Cong et~al.}}{{Cong, Liu, Neuendorffer, Noguera, Vissers, and Zhang}}}
\bibcite{cooley65}{{16}{1965}{{Cooley and Tukey}}{{}}}
\bibcite{CLR}{{17}{2009}{{Cormen et~al.}}{{Cormen, Leiserson, Rivest, and Stein}}}
\bibcite{coussy2010high}{{18}{2010}{{Coussy and Morawiec}}{{}}}
\bibcite{dai17dynamic}{{19}{2017}{{Dai et~al.}}{{Dai, Zhao, Liu, Srinath, Gupta, Batten, and Zhang}}}
\bibcite{dean08mapreduce}{{20}{2008}{{Dean and Ghemawat}}{{}}}
\bibcite{despain1974fourier}{{21}{1974}{{Despain}}{{}}}
\bibcite{detrey07hotbm}{{22}{2007}{{Detrey and de~Dinechin}}{{}}}
\bibcite{deutsch1996deflate}{{23}{1996}{{Deutsch}}{{}}}
\bibcite{duprat1993cordic}{{24}{1993}{{Duprat and Muller}}{{}}}
\bibcite{flannery1992numerical}{{25}{1992}{{Flannery et~al.}}{{Flannery, Press, Teukolsky, and Vetterling}}}
\bibcite{gajski2012high}{{26}{2012}{{Gajski et~al.}}{{Gajski, Dutt, Wu, and Lin}}}
\bibcite{gentleman1966fast}{{27}{1966}{{Gentleman and Sande}}{{}}}
\bibcite{george2014hardware}{{28}{2014}{{George et~al.}}{{George, Lee, Novo, Rompf, Brown, Sujeeth, Odersky, Olukotun, and Ienne}}}
\bibcite{gupta2004spark}{{29}{2004}{{Gupta et~al.}}{{Gupta, Gupta, Dutt, and Nicolau}}}
\bibcite{hauck2010reconfigurable}{{30}{2010}{{Hauck and DeHon}}{{}}}
\bibcite{hegarty2016rigel}{{31}{2016}{{Hegarty et~al.}}{{Hegarty, Daly, DeVito, Ragan-Kelley, Horowitz, and Hanrahan}}}
\bibcite{heideman84}{{32}{1984}{{Heideman et~al.}}{{Heideman, Johnson, and Burrus}}}
\bibcite{huffman1952method}{{33}{1952}{{Huffman}}{{}}}
\bibcite{kastner2010arithmetic}{{34}{2010}{{Kastner et~al.}}{{Kastner, Hosangadi, and Fallah}}}
\bibcite{knapp96bc}{{35}{1996}{{Knapp}}{{}}}
\bibcite{knuth1998art}{{36}{1998}{{Knuth}}{{}}}
\bibcite{Laforest2014multiport}{{37}{2014}{{Laforest et~al.}}{{Laforest, Li, O'rourke, Liu, and Steffan}}}
\bibcite{langdon1990arithmetic}{{38}{1990}{{Langdon~Jr et~al.}}{{Langdon~Jr, Mitchell, Pennebaker, and Rissanen}}}
\bibcite{lee250high}{{39}{2014}{{Lee et~al.}}{{Lee, Matai, Weals, and Kastner}}}
\bibcite{lee87sdfArchitecture}{{40}{1987}{{Lee and Messerschmitt}}{{}}}
\bibcite{lee2011signalsandsystems}{{41}{2011}{{Lee and Varaiya}}{{}}}
\bibcite{lee2017plato}{{42}{2017}{{Lee}}{{}}}
\bibcite{leiserson93}{{43}{1993}{{Leiserson et~al.}}{{Leiserson, Rose, and Saxe}}}
\bibcite{liu17elasticflow}{{44}{2017}{{Liu et~al.}}{{Liu, Tan, Dai, Zhao, and Zhang}}}
\bibcite{marcelino2008sorting}{{45}{2008}{{Marcelino et~al.}}{{}}}
\bibcite{mataidesigning}{{46}{2012}{{Matai et~al.}}{{Matai, Meng, Wu, Weals, and Kastner}}}
\bibcite{matai2energy}{{47}{2014{}}{{Matai et~al.}}{{Matai, Kim, and Kastner}}}
\bibcite{matai2014enabling}{{48}{2014{}}{{Matai et~al.}}{{Matai, Richmond, Lee, and Kastner}}}
\bibcite{matai2016sorting}{{49}{2016}{{Matai et~al.}}{{Matai, Richmond, Lee, Blair, Wu, Abazari, and Kastner}}}
\bibcite{mead1980introduction}{{50}{1980}{{Mead and Conway}}{{}}}
\bibcite{micheli1994synthesis}{{51}{1994}{{Micheli}}{{}}}
\bibcite{mirzaei2007fpga}{{52}{2007}{{Mirzaei et~al.}}{{Mirzaei, Hosangadi, and Kastner}}}
\bibcite{misra2012}{{53}{2013}{{MISRA}}{{}}}
\bibcite{mueller2012sorting}{{54}{2012}{{Mueller et~al.}}{{}}}
\bibcite{ortiz2011streaming}{{55}{2011}{{Ortiz et~al.}}{{}}}
\bibcite{papaefthymiou91}{{56}{1991}{{Papaefthymiou}}{{}}}
\bibcite{pennebaker1992jpeg}{{57}{1992}{{Pennebaker}}{{}}}
\bibcite{sedgewickalgorithmsinC}{{58}{2001}{{Sedgewick}}{{}}}
\bibcite{sherigar2004huffman}{{59}{2004}{{Sherigar and Ramanujan}}{{}}}
\bibcite{winterstein13dynamic}{{60}{2013}{{Winterstein et~al.}}{{Winterstein, Bayliss, and Constantinides}}}
\bibcite{witten1987arithmetic}{{61}{1987}{{Witten et~al.}}{{Witten, Neal, and Cleary}}}
\bibcite{ug574}{{62}{2017{}}{{Xil}}{{}}}
\bibcite{ug902}{{63}{2017{}}{{Xil}}{{}}}
\bibcite{ultrascaleArchConfig}{{64}{2017{}}{{Xil}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Glossary}{231}{section*.143}}
\@gls@reference{acronym}{rtl}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{231}}
\@gls@reference{acronym}{dft}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{231}}
\@gls@reference{main}{dftg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{231}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{main}{fpgag}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{main}{lutg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{main}{ffg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{bram}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{main}{bramg}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{lut}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{ff}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{acronym}{fpga}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{232}}
\@gls@reference{main}{routingchannel}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{233}}
\@gls@reference{main}{ioblock}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{233}}
\@writefile{toc}{\contentsline {chapter}{Acronyms}{235}{section*.145}}
\ulp@afterend
